{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/groda/big_data/blob/master/SLURM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukIg5iRf3yoD"
   },
   "source": [
    "<a href=\"https://github.com/groda/big_data\"><div><img src=\"https://github.com/groda/big_data/blob/master/logo_bdb.png?raw=true\" align=right width=\"90\" alt=\"Logo Big Data for Beginners\"></div></a>\n",
    "# SLURM Demonstration: Unleashing Parallel Computing\n",
    "\n",
    "<div width=\"110\"><img src=\"https://github.com/groda/big_data/blob/master/Slurm_logo.svg.png?raw=true\" align=left width=\"90\" style=\"margin:30px\" alt=\"SLURM logo\"/></div>\n",
    "\n",
    "\n",
    " **SLURM** is an acronym for **S**imple **L**inux **U**tility for **R**esource **M**anagement. The name reflects its original design goal of being a straightforward yet powerful tool for managing Linux cluster resources.\n",
    "\n",
    "This demonstration walks you through setting up, configuring, and using SLURM on a single Ubuntu virtual machine (VM), providing a hands-on introduction to its features for high-performance computing (HPC) environments.\n",
    "\n",
    "We‚Äôll explore how to set up and harness SLURM‚Äôs job scheduling capabilities, whether you‚Äôre using Google Colab‚Äôs cloud environment or your own virtual machine (VM). From submitting jobs to verifying parallel execution, you‚Äôll learn to leverage SLURM for efficient computation‚Äîperfect for your single-node Docker setup or beyond.\n",
    "\n",
    "To make navigation easier:\n",
    "- **üöÄ Critical Steps**: Sections marked with the üöÄ emoji highlight essential tasks, such as installation and configuration, that are crucial for setting up and running SLURM. Follow these steps carefully to ensure a successful deployment.\n",
    "- **üìù Side Notes**: Sections marked with the üìù emoji contain optional, supplementary information, such as historical context or additional tips. These can be skipped if you‚Äôre focused on the core setup process but are expandable for deeper insights.\n",
    "\n",
    "Get ready to dive into the power of SLURM for parallel computing and supercharge your workflows!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "W5_sjZ6PEAoY"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [üöÄ Install the SLURM Packages](#scrollTo=2QpF7XoRzry7)\n",
    "- [üìù Side Note: What is slurm-wlm?](#scrollTo=brQkWtmMi786)\n",
    "- [üìù Side Note: A Brief History of SLURM](#scrollTo=31Q0HgWMK19o)\n",
    "- [üìù Side Note: Debian's sid and SLURM](#scrollTo=VFtQ9QQgj98S)\n",
    "- [üìù Side Note: Nerdy Names, Serious Systems](#scrollTo=_Side_Note_Nerdy_Names_Serious_Systems)\n",
    "- [üöÄ Configuration](#scrollTo=BhhgV7kNYT7c)\n",
    "- [üìù Configure using slurm-wlm-configurator.html](#scrollTo=XhJQeLeT99Tz)\n",
    "- [üöÄ Generate a `munge` key](#scrollTo=3d8C0ay3Xa-d)\n",
    "- [üöÄ Create Spool Directories](#scrollTo=fgqo9xAZXxYS)\n",
    "- [üöÄ Start the Services](#scrollTo=gFMWSBKBX7Yl)\n",
    "- [üöÄ Verify Cluster Status](#scrollTo=92wZzJmSfK35)\n",
    "- [üìù Useful Commands for Debugging](#scrollTo=rNeusBTLcqve)\n",
    "- [üöÄ Run a simple job](#scrollTo=Ua-nBgvmsJpA)\n",
    "- [üöÄ Did the Job Run in Parallel?](#scrollTo=1DAjlH9ltWXj)\n",
    "- [üöÄ Single-task parallel Python with `multiprocessing` and `--cpus-per-task`](#scrollTo=uH60mvkDzzFk)\n",
    "- [üöÄ Run multiple tasks with `srun`](#scrollTo=Jnx75guCFmZk)\n",
    "- [üöÄ SLURM Job Arrays](#scrollTo=H-QTevQSJjJM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QpF7XoRzry7"
   },
   "source": [
    "## üöÄ Install the SLURM Packages\n",
    "\n",
    "This might take a few seconds ...\n",
    "<img src=\"data:image/gif;base64,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\" alt=\"Running cat\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:00.689163Z",
     "iopub.status.busy": "2025-11-24T08:11:00.688935Z",
     "iopub.status.idle": "2025-11-24T08:11:12.205866Z",
     "shell.execute_reply": "2025-11-24T08:11:12.205138Z"
    },
    "id": "f2r8fGUyR-7P",
    "outputId": "a55bfa40-b614-48dd-c0e7-c1a6ff18a15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 100%\r",
      "\r",
      "Reading package lists... Done\r",
      "\r\n",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree... 50%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Building dependency tree... Done\r",
      "\r\n",
      "\r",
      "Reading state information... 0% \r",
      "\r",
      "Reading state information... 0%\r",
      "\r",
      "Reading state information... Done\r",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following additional packages will be installed:\r\n",
      "  freeipmi-common libaec0 libb64-0d libdbi1t64 libfreeipmi17 libhdf5-103-1t64\r\n",
      "  libhdf5-hl-100t64 libhwloc-plugins libhwloc15 libipmimonitoring6 libjwt2\r\n",
      "  liblua5.1-0 libmunge2 liboam-dev liboam1 librocm-smi-dev librocm-smi64-1\r\n",
      "  librrd8t64 libsz2 libxnvctrl0 munge ocl-icd-libopencl1 slurm-client\r\n",
      "  slurm-wlm-basic-plugins slurm-wlm-basic-plugins-dev\r\n",
      "  slurm-wlm-elasticsearch-plugin slurm-wlm-elasticsearch-plugin-dev\r\n",
      "  slurm-wlm-hdf5-plugin slurm-wlm-hdf5-plugin-dev slurm-wlm-influxdb-plugin\r\n",
      "  slurm-wlm-influxdb-plugin-dev slurm-wlm-ipmi-plugins\r\n",
      "  slurm-wlm-ipmi-plugins-dev slurm-wlm-jwt-plugin slurm-wlm-jwt-plugin-dev\r\n",
      "  slurm-wlm-mysql-plugin-dev slurm-wlm-plugins slurm-wlm-plugins-dev\r\n",
      "  slurm-wlm-rrd-plugin slurm-wlm-rrd-plugin-dev slurm-wlm-rsmi-plugin\r\n",
      "  slurm-wlm-rsmi-plugin-dev slurmctld slurmd\r\n",
      "Suggested packages:\r\n",
      "  freeipmi-tools libhwloc-contrib-plugins opencl-icd\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following NEW packages will be installed:\r\n",
      "  freeipmi-common libaec0 libb64-0d libdbi1t64 libfreeipmi17 libhdf5-103-1t64\r\n",
      "  libhdf5-hl-100t64 libhwloc-plugins libhwloc15 libipmimonitoring6 libjwt2\r\n",
      "  liblua5.1-0 libmunge2 liboam-dev liboam1 librocm-smi-dev librocm-smi64-1\r\n",
      "  librrd8t64 libsz2 libxnvctrl0 munge ocl-icd-libopencl1 slurm-client\r\n",
      "  slurm-wlm slurm-wlm-basic-plugins slurm-wlm-basic-plugins-dev\r\n",
      "  slurm-wlm-elasticsearch-plugin slurm-wlm-elasticsearch-plugin-dev\r\n",
      "  slurm-wlm-hdf5-plugin slurm-wlm-hdf5-plugin-dev slurm-wlm-influxdb-plugin\r\n",
      "  slurm-wlm-influxdb-plugin-dev slurm-wlm-ipmi-plugins\r\n",
      "  slurm-wlm-ipmi-plugins-dev slurm-wlm-jwt-plugin slurm-wlm-jwt-plugin-dev\r\n",
      "  slurm-wlm-mysql-plugin-dev slurm-wlm-plugins slurm-wlm-plugins-dev\r\n",
      "  slurm-wlm-rrd-plugin slurm-wlm-rrd-plugin-dev slurm-wlm-rsmi-plugin\r\n",
      "  slurm-wlm-rsmi-plugin-dev slurmctld slurmd\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 upgraded, 45 newly installed, 0 to remove and 49 not upgraded.\r\n",
      "Need to get 44.6 MB of archives.\r\n",
      "After this operation, 84.8 MB of additional disk space will be used.\r\n",
      "\u001b[33m\r",
      "0% [Working]\u001b[0m\r",
      "            \r",
      "Get:1 file:/etc/apt/apt-mirrors.txt Mirrorlist [144 B]\r\n",
      "\u001b[33m\r",
      "0% [1 Mirrorlist 0 B/144 B 0%]\u001b[0m\u001b[33m\r",
      "                              \r",
      "0% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m\u001b[33m\r",
      "0% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:2 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 liblua5.1-0 amd64 5.1.5-9build2 [120 kB]\r\n",
      "\u001b[33m\r",
      "0% [2 liblua5.1-0 2454 B/120 kB 2%]\u001b[0m\u001b[33m\r",
      "                                   \r",
      "1% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:3 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libhwloc15 amd64 2.10.0-1build1 [172 kB]\r\n",
      "\u001b[33m\r",
      "1% [3 libhwloc15 8192 B/172 kB 5%]\u001b[0m\u001b[33m\r",
      "                                  \r",
      "2% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:4 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libb64-0d amd64 1.2-5 [9324 B]\r\n",
      "\u001b[33m\r",
      "2% [4 libb64-0d 3885 B/9324 B 42%]\u001b[0m\u001b[33m\r",
      "                                  \r",
      "2% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:5 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libjwt2 amd64 1.17.0-2build2 [17.5 kB]\r\n",
      "\u001b[33m\r",
      "2% [5 libjwt2 12.3 kB/17.5 kB 70%]\u001b[0m\u001b[33m\r",
      "                                  \r",
      "3% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:6 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libmunge2 amd64 0.5.15-4build1 [14.7 kB]\r\n",
      "\u001b[33m\r",
      "3% [6 libmunge2 8192 B/14.7 kB 56%]\u001b[0m\u001b[33m\r",
      "                                   \r",
      "3% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:7 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-basic-plugins amd64 23.11.4-1.2ubuntu5 [2103 kB]\r\n",
      "\u001b[33m\r",
      "3% [7 slurm-wlm-basic-plugins 31.1 kB/2103 kB 1%]\u001b[0m\u001b[33m\r",
      "                                                 \r",
      "7% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:8 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 munge amd64 0.5.15-4build1 [102 kB]\r\n",
      "\u001b[33m\r",
      "7% [8 munge 8192 B/102 kB 8%]\u001b[0m\u001b[33m\r",
      "                             \r",
      "8% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:9 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-client amd64 23.11.4-1.2ubuntu5 [848 kB]\r\n",
      "\u001b[33m\r",
      "8% [9 slurm-client 0 B/848 kB 0%]\u001b[0m\u001b[33m\r",
      "                                 \r",
      "10% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:10 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurmctld amd64 23.11.4-1.2ubuntu5 [540 kB]\r\n",
      "\u001b[33m\r",
      "10% [10 slurmctld 45.1 kB/540 kB 8%]\u001b[0m\u001b[33m\r",
      "                                    \r",
      "11% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:11 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurmd amd64 23.11.4-1.2ubuntu5 [211 kB]\r\n",
      "\u001b[33m\r",
      "11% [11 slurmd 31.4 kB/211 kB 15%]\u001b[0m\u001b[33m\r",
      "                                  \r",
      "12% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:12 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libaec0 amd64 1.1.2-1build1 [22.9 kB]\r\n",
      "\u001b[33m\r",
      "12% [12 libaec0 22.9 kB/22.9 kB 100%]\u001b[0m\u001b[33m\r",
      "                                     \r",
      "13% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:13 http://azure.archive.ubuntu.com/ubuntu noble/main amd64 libdbi1t64 amd64 0.9.0-6.1build1 [25.7 kB]\r\n",
      "\u001b[33m\r",
      "13% [13 libdbi1t64 24.6 kB/25.7 kB 96%]\u001b[0m\u001b[33m\r",
      "                                       \r",
      "13% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:14 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libsz2 amd64 1.1.2-1build1 [5476 B]\r\n",
      "\u001b[33m\r",
      "13% [14 libsz2 5476 B/5476 B 100%]\u001b[0m\u001b[33m\r",
      "                                  \r",
      "14% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:15 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libhdf5-103-1t64 amd64 1.10.10+repack-3.1ubuntu4 [1270 kB]\r\n",
      "\u001b[33m\r",
      "14% [15 libhdf5-103-1t64 28.7 kB/1270 kB 2%]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\r",
      "                                            \r",
      "16% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:16 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libhdf5-hl-100t64 amd64 1.10.10+repack-3.1ubuntu4 [56.0 kB]\r\n",
      "\u001b[33m\r",
      "16% [16 libhdf5-hl-100t64 20.5 kB/56.0 kB 37%]\u001b[0m\u001b[33m\r",
      "                                              \r",
      "17% [Working]\u001b[0m\r",
      "             \r",
      "Get:17 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 liboam1 amd64 5.7.0-1 [315 kB]\r\n",
      "\u001b[33m\r",
      "17% [17 liboam1 8221 B/315 kB 3%]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\r",
      "                                 \r",
      "18% [Working]\u001b[0m\r",
      "             \r",
      "Get:18 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 liboam-dev amd64 5.7.0-1 [7250 B]\r\n",
      "\u001b[33m\r",
      "18% [18 liboam-dev 7250 B/7250 B 100%]\u001b[0m\u001b[33m\r",
      "                                      \r",
      "18% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:19 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 librocm-smi64-1 amd64 5.7.0-1 [309 kB]\r\n",
      "\u001b[33m\r",
      "18% [19 librocm-smi64-1 32.8 kB/309 kB 11%]\u001b[0m\u001b[33m\r",
      "                                           \r",
      "19% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:20 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 librocm-smi-dev amd64 5.7.0-1 [35.4 kB]\r\n",
      "\u001b[33m\r",
      "19% [20 librocm-smi-dev 20.5 kB/35.4 kB 58%]\u001b[0m\u001b[33m\r",
      "                                            \r",
      "20% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:21 http://azure.archive.ubuntu.com/ubuntu noble/main amd64 librrd8t64 amd64 1.7.2-4.1ubuntu3 [172 kB]\r\n",
      "\u001b[33m\r",
      "20% [21 librrd8t64 8192 B/172 kB 5%]\u001b[0m\u001b[33m\r",
      "                                    \r",
      "21% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:22 http://azure.archive.ubuntu.com/ubuntu noble/main amd64 libxnvctrl0 amd64 510.47.03-0ubuntu4 [12.6 kB]\r\n",
      "\u001b[33m\r",
      "21% [22 libxnvctrl0 8192 B/12.6 kB 65%]\u001b[0m\u001b[33m\r",
      "                                       \r",
      "21% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:23 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm amd64 23.11.4-1.2ubuntu5 [287 kB]\r\n",
      "\u001b[33m\r",
      "21% [23 slurm-wlm 1081 B/287 kB 0%]\u001b[0m\u001b[33m\r",
      "                                   \r",
      "22% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:24 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-basic-plugins-dev amd64 23.11.4-1.2ubuntu5 [33.5 MB]\r\n",
      "\u001b[33m\r",
      "22% [24 slurm-wlm-basic-plugins-dev 8192 B/33.5 MB 0%]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\r",
      "                                                      \r",
      "82% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:25 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-elasticsearch-plugin amd64 23.11.4-1.2ubuntu5 [22.4 kB]\r\n",
      "\u001b[33m\r",
      "83% [25 slurm-wlm-elasticsearch-plugin 20.5 kB/22.4 kB 92%]\u001b[0m\u001b[33m\r",
      "                                                           \r",
      "83% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:26 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-elasticsearch-plugin-dev amd64 23.11.4-1.2ubuntu5 [113 kB]\r\n",
      "\u001b[33m\r",
      "83% [26 slurm-wlm-elasticsearch-plugin-dev 8191 B/113 kB 7%]\u001b[0m\u001b[33m\r",
      "                                                            \r",
      "84% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:27 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-hdf5-plugin amd64 23.11.4-1.2ubuntu5 [37.2 kB]\r\n",
      "\u001b[33m\r",
      "84% [27 slurm-wlm-hdf5-plugin 4096 B/37.2 kB 11%]\u001b[0m\u001b[33m\r",
      "                                                 \r",
      "84% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:28 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-hdf5-plugin-dev amd64 23.11.4-1.2ubuntu5 [94.1 kB]\r\n",
      "\u001b[33m\r",
      "84% [28 slurm-wlm-hdf5-plugin-dev 20.5 kB/94.1 kB 22%]\u001b[0m\u001b[33m\r",
      "                                                      \r",
      "85% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:29 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-influxdb-plugin amd64 23.11.4-1.2ubuntu5 [19.6 kB]\r\n",
      "\u001b[33m\r",
      "85% [29 slurm-wlm-influxdb-plugin 19.6 kB/19.6 kB 100%]\u001b[0m\u001b[33m\r",
      "                                                       \r",
      "85% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:30 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-influxdb-plugin-dev amd64 23.11.4-1.2ubuntu5 [75.2 kB]\r\n",
      "\u001b[33m\r",
      "85% [30 slurm-wlm-influxdb-plugin-dev 0 B/75.2 kB 0%]\u001b[0m\u001b[33m\r",
      "                                                     \r",
      "86% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:31 http://azure.archive.ubuntu.com/ubuntu noble/main amd64 freeipmi-common all 1.6.13-3 [182 kB]\r\n",
      "\u001b[33m\r",
      "86% [31 freeipmi-common 24.6 kB/182 kB 14%]\u001b[0m\u001b[33m\r",
      "                                           \r",
      "86% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:32 http://azure.archive.ubuntu.com/ubuntu noble/main amd64 libfreeipmi17 amd64 1.6.13-3 [942 kB]\r\n",
      "\u001b[33m\r",
      "87% [32 libfreeipmi17 8919 B/942 kB 1%]\u001b[0m\u001b[33m\r",
      "                                       \r",
      "89% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:33 http://azure.archive.ubuntu.com/ubuntu noble/main amd64 libipmimonitoring6 amd64 1.6.13-3 [26.0 kB]\r\n",
      "\u001b[33m\r",
      "89% [33 libipmimonitoring6 24.6 kB/26.0 kB 95%]\u001b[0m\u001b[33m\r",
      "                                               \r",
      "89% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:34 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-ipmi-plugins amd64 23.11.4-1.2ubuntu5 [33.8 kB]\r\n",
      "\u001b[33m\r",
      "89% [34 slurm-wlm-ipmi-plugins 22.7 kB/33.8 kB 67%]\u001b[0m\u001b[33m\r",
      "                                                   \r",
      "90% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:35 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-ipmi-plugins-dev amd64 23.11.4-1.2ubuntu5 [226 kB]\r\n",
      "\u001b[33m\r",
      "90% [35 slurm-wlm-ipmi-plugins-dev 20.5 kB/226 kB 9%]\u001b[0m\u001b[33m\r",
      "                                                     \r",
      "90% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:36 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-jwt-plugin amd64 23.11.4-1.2ubuntu5 [21.0 kB]\r\n",
      "\u001b[33m\r",
      "90% [36 slurm-wlm-jwt-plugin 21.0 kB/21.0 kB 100%]\u001b[0m\u001b[33m\r",
      "                                                  \r",
      "91% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:37 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-jwt-plugin-dev amd64 23.11.4-1.2ubuntu5 [82.4 kB]\r\n",
      "\u001b[33m\r",
      "91% [37 slurm-wlm-jwt-plugin-dev 36.9 kB/82.4 kB 45%]\u001b[0m\u001b[33m\r",
      "                                                     \r",
      "91% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:38 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-mysql-plugin-dev amd64 23.11.4-1.2ubuntu5 [2238 kB]\r\n",
      "\u001b[33m\r",
      "92% [38 slurm-wlm-mysql-plugin-dev 5308 B/2238 kB 0%]\u001b[0m\u001b[33m\r",
      "                                                     \r",
      "96% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:39 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-rrd-plugin amd64 23.11.4-1.2ubuntu5 [19.9 kB]\r\n",
      "\u001b[33m\r",
      "96% [39 slurm-wlm-rrd-plugin 4096 B/19.9 kB 21%]\u001b[0m\u001b[33m\r",
      "                                                \r",
      "96% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:40 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-rsmi-plugin amd64 23.11.4-1.2ubuntu5 [24.4 kB]\r\n",
      "\u001b[33m\r",
      "96% [40 slurm-wlm-rsmi-plugin 20.0 kB/24.4 kB 82%]\u001b[0m\u001b[33m\r",
      "                                                  \r",
      "97% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:41 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-plugins amd64 23.11.4-1.2ubuntu5 [12.4 kB]\r\n",
      "\u001b[33m\r",
      "97% [41 slurm-wlm-plugins 8192 B/12.4 kB 66%]\u001b[0m\u001b[33m\r",
      "                                             \r",
      "97% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:42 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-rrd-plugin-dev amd64 23.11.4-1.2ubuntu5 [71.6 kB]\r\n",
      "\u001b[33m\r",
      "97% [42 slurm-wlm-rrd-plugin-dev 28.7 kB/71.6 kB 40%]\u001b[0m\u001b[33m\r",
      "                                                     \r",
      "98% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:43 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-rsmi-plugin-dev amd64 23.11.4-1.2ubuntu5 [129 kB]\r\n",
      "\u001b[33m\r",
      "98% [43 slurm-wlm-rsmi-plugin-dev 8192 B/129 kB 6%]\u001b[0m\u001b[33m\r",
      "                                                   \r",
      "99% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:44 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 slurm-wlm-plugins-dev amd64 23.11.4-1.2ubuntu5 [12.4 kB]\r\n",
      "\u001b[33m\r",
      "99% [44 slurm-wlm-plugins-dev 8192 B/12.4 kB 66%]\u001b[0m\u001b[33m\r",
      "                                                 \r",
      "99% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:45 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 ocl-icd-libopencl1 amd64 2.3.2-1build1 [38.5 kB]\r\n",
      "\u001b[33m\r",
      "99% [45 ocl-icd-libopencl1 10.7 kB/38.5 kB 28%]\u001b[0m\u001b[33m\r",
      "                                               \r",
      "100% [Working]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "              \r",
      "Get:46 http://azure.archive.ubuntu.com/ubuntu noble/universe amd64 libhwloc-plugins amd64 2.10.0-1build1 [15.7 kB]\r\n",
      "\u001b[33m\r",
      "100% [46 libhwloc-plugins 8192 B/15.7 kB 52%]\u001b[0m\u001b[33m\r",
      "                                             \r",
      "100% [Working]\u001b[0m\r",
      "              \r",
      "Fetched 44.6 MB in 3s (15.8 MB/s)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Extracting templates from packages: 66%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Extracting templates from packages: 100%\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package liblua5.1-0:amd64.\r\n",
      "(Reading database ... \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 65%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 70%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 75%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 85%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 90%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 95%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 100%\r",
      "(Reading database ... 216225 files and directories currently installed.)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../00-liblua5.1-0_5.1.5-9build2_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking liblua5.1-0:amd64 (5.1.5-9build2) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  1%]\u001b[49m\u001b[39m [..........................................................] \u001b8Selecting previously unselected package libhwloc15:amd64.\r\n",
      "Preparing to unpack .../01-libhwloc15_2.10.0-1build1_amd64.deb ...\r\n",
      "Unpacking libhwloc15:amd64 (2.10.0-1build1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package libb64-0d:amd64.\r\n",
      "Preparing to unpack .../02-libb64-0d_1.2-5_amd64.deb ...\r\n",
      "Unpacking libb64-0d:amd64 (1.2-5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libjwt2:amd64.\r\n",
      "Preparing to unpack .../03-libjwt2_1.17.0-2build2_amd64.deb ...\r\n",
      "Unpacking libjwt2:amd64 (1.17.0-2build2) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Selecting previously unselected package libmunge2:amd64.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../04-libmunge2_0.5.15-4build1_amd64.deb ...\r\n",
      "Unpacking libmunge2:amd64 (0.5.15-4build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package slurm-wlm-basic-plugins.\r\n",
      "Preparing to unpack .../05-slurm-wlm-basic-plugins_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useradd warning: slurm's uid 64030 is greater than SYS_UID_MAX 999\r\n",
      "Unpacking slurm-wlm-basic-plugins (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package munge.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../06-munge_0.5.15-4build1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking munge (0.5.15-4build1) ...\r\n",
      "Selecting previously unselected package slurm-client.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../07-slurm-client_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking slurm-client (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurmctld.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../08-slurmctld_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking slurmctld (23.11.4-1.2ubuntu5) ...\r\n",
      "Selecting previously unselected package slurmd.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../09-slurmd_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking slurmd (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libaec0:amd64.\r\n",
      "Preparing to unpack .../10-libaec0_1.1.2-1build1_amd64.deb ...\r\n",
      "Unpacking libaec0:amd64 (1.1.2-1build1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libdbi1t64:amd64.\r\n",
      "Preparing to unpack .../11-libdbi1t64_0.9.0-6.1build1_amd64.deb ...\r\n",
      "Unpacking libdbi1t64:amd64 (0.9.0-6.1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libsz2:amd64.\r\n",
      "Preparing to unpack .../12-libsz2_1.1.2-1build1_amd64.deb ...\r\n",
      "Unpacking libsz2:amd64 (1.1.2-1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libhdf5-103-1t64:amd64.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../13-libhdf5-103-1t64_1.10.10+repack-3.1ubuntu4_amd64.deb ...\r\n",
      "Unpacking libhdf5-103-1t64:amd64 (1.10.10+repack-3.1ubuntu4) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libhdf5-hl-100t64:amd64.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../14-libhdf5-hl-100t64_1.10.10+repack-3.1ubuntu4_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libhdf5-hl-100t64:amd64 (1.10.10+repack-3.1ubuntu4) ...\r\n",
      "Selecting previously unselected package liboam1.\r\n",
      "Preparing to unpack .../15-liboam1_5.7.0-1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking liboam1 (5.7.0-1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package liboam-dev.\r\n",
      "Preparing to unpack .../16-liboam-dev_5.7.0-1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking liboam-dev (5.7.0-1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package librocm-smi64-1.\r\n",
      "Preparing to unpack .../17-librocm-smi64-1_5.7.0-1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking librocm-smi64-1 (5.7.0-1) ...\r\n",
      "Selecting previously unselected package librocm-smi-dev.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../18-librocm-smi-dev_5.7.0-1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking librocm-smi-dev (5.7.0-1) ...\r\n",
      "Selecting previously unselected package librrd8t64:amd64.\r\n",
      "Preparing to unpack .../19-librrd8t64_1.7.2-4.1ubuntu3_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking librrd8t64:amd64 (1.7.2-4.1ubuntu3) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package libxnvctrl0:amd64.\r\n",
      "Preparing to unpack .../20-libxnvctrl0_510.47.03-0ubuntu4_amd64.deb ...\r\n",
      "Unpacking libxnvctrl0:amd64 (510.47.03-0ubuntu4) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm.\r\n",
      "Preparing to unpack .../21-slurm-wlm_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package slurm-wlm-basic-plugins-dev.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../22-slurm-wlm-basic-plugins-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm-basic-plugins-dev (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm-elasticsearch-plugin.\r\n",
      "Preparing to unpack .../23-slurm-wlm-elasticsearch-plugin_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm-elasticsearch-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package slurm-wlm-elasticsearch-plugin-dev.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../24-slurm-wlm-elasticsearch-plugin-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking slurm-wlm-elasticsearch-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "Selecting previously unselected package slurm-wlm-hdf5-plugin.\r\n",
      "Preparing to unpack .../25-slurm-wlm-hdf5-plugin_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking slurm-wlm-hdf5-plugin (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm-hdf5-plugin-dev.\r\n",
      "Preparing to unpack .../26-slurm-wlm-hdf5-plugin-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking slurm-wlm-hdf5-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm-influxdb-plugin.\r\n",
      "Preparing to unpack .../27-slurm-wlm-influxdb-plugin_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking slurm-wlm-influxdb-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "Selecting previously unselected package slurm-wlm-influxdb-plugin-dev.\r\n",
      "Preparing to unpack .../28-slurm-wlm-influxdb-plugin-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking slurm-wlm-influxdb-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package freeipmi-common.\r\n",
      "Preparing to unpack .../29-freeipmi-common_1.6.13-3_all.deb ...\r\n",
      "Unpacking freeipmi-common (1.6.13-3) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libfreeipmi17.\r\n",
      "Preparing to unpack .../30-libfreeipmi17_1.6.13-3_amd64.deb ...\r\n",
      "Unpacking libfreeipmi17 (1.6.13-3) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libipmimonitoring6.\r\n",
      "Preparing to unpack .../31-libipmimonitoring6_1.6.13-3_amd64.deb ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking libipmimonitoring6 (1.6.13-3) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package slurm-wlm-ipmi-plugins.\r\n",
      "Preparing to unpack .../32-slurm-wlm-ipmi-plugins_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm-ipmi-plugins (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm-ipmi-plugins-dev.\r\n",
      "Preparing to unpack .../33-slurm-wlm-ipmi-plugins-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking slurm-wlm-ipmi-plugins-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "Selecting previously unselected package slurm-wlm-jwt-plugin.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../34-slurm-wlm-jwt-plugin_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking slurm-wlm-jwt-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "Selecting previously unselected package slurm-wlm-jwt-plugin-dev.\r\n",
      "Preparing to unpack .../35-slurm-wlm-jwt-plugin-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking slurm-wlm-jwt-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm-mysql-plugin-dev.\r\n",
      "Preparing to unpack .../36-slurm-wlm-mysql-plugin-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking slurm-wlm-mysql-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm-rrd-plugin.\r\n",
      "Preparing to unpack .../37-slurm-wlm-rrd-plugin_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking slurm-wlm-rrd-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "Selecting previously unselected package slurm-wlm-rsmi-plugin.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../38-slurm-wlm-rsmi-plugin_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking slurm-wlm-rsmi-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Selecting previously unselected package slurm-wlm-plugins.\r\n",
      "Preparing to unpack .../39-slurm-wlm-plugins_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm-plugins (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package slurm-wlm-rrd-plugin-dev.\r\n",
      "Preparing to unpack .../40-slurm-wlm-rrd-plugin-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm-rrd-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package slurm-wlm-rsmi-plugin-dev.\r\n",
      "Preparing to unpack .../41-slurm-wlm-rsmi-plugin-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm-rsmi-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package slurm-wlm-plugins-dev.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../42-slurm-wlm-plugins-dev_23.11.4-1.2ubuntu5_amd64.deb ...\r\n",
      "Unpacking slurm-wlm-plugins-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Selecting previously unselected package ocl-icd-libopencl1:amd64.\r\n",
      "Preparing to unpack .../43-ocl-icd-libopencl1_2.3.2-1build1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking ocl-icd-libopencl1:amd64 (2.3.2-1build1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libhwloc-plugins:amd64.\r\n",
      "Preparing to unpack .../44-libhwloc-plugins_2.10.0-1build1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking libhwloc-plugins:amd64 (2.10.0-1build1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up freeipmi-common (1.6.13-3) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libdbi1t64:amd64 (0.9.0-6.1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up liboam1 (5.7.0-1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up libb64-0d:amd64 (1.2-5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libjwt2:amd64 (1.17.0-2build2) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libaec0:amd64 (1.1.2-1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libxnvctrl0:amd64 (510.47.03-0ubuntu4) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up liboam-dev (5.7.0-1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up libmunge2:amd64 (0.5.15-4build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libhwloc15:amd64 (2.10.0-1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libfreeipmi17 (1.6.13-3) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up ocl-icd-libopencl1:amd64 (2.3.2-1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up liblua5.1-0:amd64 (5.1.5-9build2) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up librrd8t64:amd64 (1.7.2-4.1ubuntu3) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libsz2:amd64 (1.1.2-1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up librocm-smi64-1 (5.7.0-1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up munge (0.5.15-4build1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink /etc/systemd/system/multi-user.target.wants/munge.service ‚Üí /usr/lib/systemd/system/munge.service.\r",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libhwloc-plugins:amd64 (2.10.0-1build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libipmimonitoring6 (1.6.13-3) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up slurm-wlm-basic-plugins (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up librocm-smi-dev (5.7.0-1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up slurmd (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8update-alternatives: using /usr/sbin/slurmd-wlm to provide /usr/sbin/slurmd (slurmd) in auto mode\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink /etc/systemd/system/multi-user.target.wants/slurmd.service ‚Üí /usr/lib/systemd/system/slurmd.service.\r",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not execute systemctl:  at /usr/bin/deb-systemd-invoke line 148.\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up slurm-wlm-influxdb-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libhdf5-103-1t64:amd64 (1.10.10+repack-3.1ubuntu4) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up libhdf5-hl-100t64:amd64 (1.10.10+repack-3.1ubuntu4) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up slurm-wlm-basic-plugins-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up slurm-wlm-rrd-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up slurm-wlm-ipmi-plugins (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up slurm-wlm-elasticsearch-plugin (23.11.4-1.2ubuntu5) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up slurm-wlm-jwt-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up slurm-wlm-influxdb-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up slurm-client (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up slurmctld (23.11.4-1.2ubuntu5) ...\r\n",
      "update-alternatives: using /usr/sbin/slurmctld-wlm to provide /usr/sbin/slurmctld (slurmctld) in auto mode\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink /etc/systemd/system/multi-user.target.wants/slurmctld.service ‚Üí /usr/lib/systemd/system/slurmctld.service.\r",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up slurm-wlm-ipmi-plugins-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up slurm-wlm-hdf5-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up slurm-wlm-rsmi-plugin (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up slurm-wlm-elasticsearch-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up slurm-wlm-hdf5-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up slurm-wlm-mysql-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up slurm-wlm (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up slurm-wlm-rrd-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up slurm-wlm-plugins (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up slurm-wlm-jwt-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Setting up slurm-wlm-rsmi-plugin-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [#########################################################.] \u001b8Setting up slurm-wlm-plugins-dev (23.11.4-1.2ubuntu5) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8Processing triggers for libc-bin (2.39-0ubuntu8.6) ...\r\n",
      "Processing triggers for man-db (2.12.0-4build2) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not building database; man-db/auto-update is not 'true'.\r\n",
      "Processing triggers for install-info (7.1-3build2) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning processes... [                                                        ]\r",
      "Scanning processes... [                                                        ]\r",
      "Scanning processes... [                                                        ]\r",
      "Scanning processes... [                                                        ]\r",
      "Scanning processes... [=                                                       ]\r",
      "Scanning processes... [=                                                       ]\r",
      "Scanning processes... [=                                                       ]\r",
      "Scanning processes... [==                                                      ]\r",
      "Scanning processes... [==                                                      ]\r",
      "Scanning processes... [==                                                      ]\r",
      "Scanning processes... [===                                                     ]\r",
      "Scanning processes... [===                                                     ]\r",
      "Scanning processes... [===                                                     ]\r",
      "Scanning processes... [====                                                    ]\r",
      "Scanning processes... [====                                                    ]\r",
      "Scanning processes... [====                                                    ]\r",
      "Scanning processes... [=====                                                   ]\r",
      "Scanning processes... [=====                                                   ]\r",
      "Scanning processes... [=====                                                   ]\r",
      "Scanning processes... [======                                                  ]\r",
      "Scanning processes... [======                                                  ]\r",
      "Scanning processes... [======                                                  ]\r",
      "Scanning processes... [=======                                                 ]\r",
      "Scanning processes... [=======                                                 ]\r",
      "Scanning processes... [=======                                                 ]\r",
      "Scanning processes... [========                                                ]\r",
      "Scanning processes... [========                                                ]\r",
      "Scanning processes... [========                                                ]\r",
      "Scanning processes... [=========                                               ]\r",
      "Scanning processes... [=========                                               ]\r",
      "Scanning processes... [=========                                               ]\r",
      "Scanning processes... [==========                                              ]\r",
      "Scanning processes... [==========                                              ]\r",
      "Scanning processes... [==========                                              ]\r",
      "Scanning processes... [===========                                             ]\r",
      "Scanning processes... [===========                                             ]\r",
      "Scanning processes... [===========                                             ]\r",
      "Scanning processes... [============                                            ]\r",
      "Scanning processes... [============                                            ]\r",
      "Scanning processes... [============                                            ]\r",
      "Scanning processes... [=============                                           ]\r",
      "Scanning processes... [=============                                           ]\r",
      "Scanning processes... [=============                                           ]\r",
      "Scanning processes... [==============                                          ]\r",
      "Scanning processes... [==============                                          ]\r",
      "Scanning processes... [==============                                          ]\r",
      "Scanning processes... [===============                                         ]\r",
      "Scanning processes... [===============                                         ]\r",
      "Scanning processes... [===============                                         ]\r",
      "Scanning processes... [================                                        ]\r",
      "Scanning processes... [================                                        ]\r",
      "Scanning processes... [================                                        ]\r",
      "Scanning processes... [=================                                       ]\r",
      "Scanning processes... [=================                                       ]\r",
      "Scanning processes... [=================                                       ]\r",
      "Scanning processes... [==================                                      ]\r",
      "Scanning processes... [==================                                      ]\r",
      "Scanning processes... [==================                                      ]\r",
      "Scanning processes... [==================                                      ]\r",
      "Scanning processes... [===================                                     ]\r",
      "Scanning processes... [===================                                     ]\r",
      "Scanning processes... [===================                                     ]\r",
      "Scanning processes... [====================                                    ]\r",
      "Scanning processes... [====================                                    ]\r",
      "Scanning processes... [====================                                    ]\r",
      "Scanning processes... [=====================                                   ]\r",
      "Scanning processes... [=====================                                   ]\r",
      "Scanning processes... [=====================                                   ]\r",
      "Scanning processes... [======================                                  ]\r",
      "Scanning processes... [======================                                  ]\r",
      "Scanning processes... [======================                                  ]\r",
      "Scanning processes... [=======================                                 ]\r",
      "Scanning processes... [=======================                                 ]\r",
      "Scanning processes... [=======================                                 ]\r",
      "Scanning processes... [========================                                ]\r",
      "Scanning processes... [========================                                ]\r",
      "Scanning processes... [========================                                ]\r",
      "Scanning processes... [=========================                               ]\r",
      "Scanning processes... [=========================                               ]\r",
      "Scanning processes... [=========================                               ]\r",
      "Scanning processes... [==========================                              ]\r",
      "Scanning processes... [==========================                              ]\r",
      "Scanning processes... [==========================                              ]\r",
      "Scanning processes... [===========================                             ]\r",
      "Scanning processes... [===========================                             ]\r",
      "Scanning processes... [===========================                             ]\r",
      "Scanning processes... [============================                            ]\r",
      "Scanning processes... [============================                            ]\r",
      "Scanning processes... [============================                            ]\r",
      "Scanning processes... [=============================                           ]\r",
      "Scanning processes... [=============================                           ]\r",
      "Scanning processes... [=============================                           ]\r",
      "Scanning processes... [==============================                          ]\r",
      "Scanning processes... [==============================                          ]\r",
      "Scanning processes... [==============================                          ]\r",
      "Scanning processes... [===============================                         ]\r",
      "Scanning processes... [===============================                         ]\r",
      "Scanning processes... [===============================                         ]\r",
      "Scanning processes... [================================                        ]\r",
      "Scanning processes... [================================                        ]\r",
      "Scanning processes... [================================                        ]\r",
      "Scanning processes... [=================================                       ]\r",
      "Scanning processes... [=================================                       ]\r",
      "Scanning processes... [=================================                       ]\r",
      "Scanning processes... [==================================                      ]\r",
      "Scanning processes... [==================================                      ]\r",
      "Scanning processes... [==================================                      ]\r",
      "Scanning processes... [===================================                     ]\r",
      "Scanning processes... [===================================                     ]\r",
      "Scanning processes... [===================================                     ]\r",
      "Scanning processes... [====================================                    ]\r",
      "Scanning processes... [====================================                    ]\r",
      "Scanning processes... [====================================                    ]\r",
      "Scanning processes... [=====================================                   ]\r",
      "Scanning processes... [=====================================                   ]\r",
      "Scanning processes... [=====================================                   ]\r",
      "Scanning processes... [=====================================                   ]\r",
      "Scanning processes... [======================================                  ]\r",
      "Scanning processes... [======================================                  ]\r",
      "Scanning processes... [======================================                  ]\r",
      "Scanning processes... [=======================================                 ]\r",
      "Scanning processes... [=======================================                 ]\r",
      "Scanning processes... [=======================================                 ]\r",
      "Scanning processes... [========================================                ]\r",
      "Scanning processes... [========================================                ]\r",
      "Scanning processes... [========================================                ]\r",
      "Scanning processes... [=========================================               ]\r",
      "Scanning processes... [=========================================               ]\r",
      "Scanning processes... [=========================================               ]\r",
      "Scanning processes... [==========================================              ]\r",
      "Scanning processes... [==========================================              ]\r",
      "Scanning processes... [==========================================              ]\r",
      "Scanning processes... [===========================================             ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning processes... [===========================================             ]\r",
      "Scanning processes... [===========================================             ]\r",
      "Scanning processes... [============================================            ]\r",
      "Scanning processes... [============================================            ]\r",
      "Scanning processes... [============================================            ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning processes... [=============================================           ]\r",
      "Scanning processes... [=============================================           ]\r",
      "Scanning processes... [=============================================           ]\r",
      "Scanning processes... [==============================================          ]\r",
      "Scanning processes... [==============================================          ]\r",
      "Scanning processes... [==============================================          ]\r",
      "Scanning processes... [===============================================         ]\r",
      "Scanning processes... [===============================================         ]\r",
      "Scanning processes... [===============================================         ]\r",
      "Scanning processes... [================================================        ]\r",
      "Scanning processes... [================================================        ]\r",
      "Scanning processes... [================================================        ]\r",
      "Scanning processes... [=================================================       ]\r",
      "Scanning processes... [=================================================       ]\r",
      "Scanning processes... [=================================================       ]\r",
      "Scanning processes... [==================================================      ]\r",
      "Scanning processes... [==================================================      ]\r",
      "Scanning processes... [==================================================      ]\r",
      "Scanning processes... [===================================================     ]\r",
      "Scanning processes... [===================================================     ]\r",
      "Scanning processes... [===================================================     ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning processes... [====================================================    ]\r",
      "Scanning processes... [====================================================    ]\r",
      "Scanning processes... [====================================================    ]\r",
      "Scanning processes... [=====================================================   ]\r",
      "Scanning processes... [=====================================================   ]\r",
      "Scanning processes... [=====================================================   ]\r",
      "Scanning processes... [======================================================  ]\r",
      "Scanning processes... [======================================================  ]\r",
      "Scanning processes... [======================================================  ]\r",
      "Scanning processes... [======================================================= ]\r",
      "Scanning processes... [======================================================= ]\r",
      "Scanning processes... [======================================================= ]\r",
      "Scanning processes... [========================================================]\r",
      "Scanning processes...                                                           \r\n",
      "Scanning candidates... [                                                       ]\r",
      "Scanning candidates... [=======================================================]\r",
      "Scanning candidates...                                                          \r\n",
      "Scanning linux images... [                                                     ]\r",
      "Scanning linux images... [=================                                    ]\r",
      "Scanning linux images... [===================================                  ]\r",
      "Scanning linux images... [=====================================================]\r",
      "Scanning linux images...                                                        \r\n",
      "\r\n",
      "Running kernel seems to be up-to-date.\r\n",
      "\r\n",
      "No services need to be restarted.\r\n",
      "\r\n",
      "No containers need to be restarted.\r\n",
      "\r\n",
      "No user sessions are running outdated binaries.\r\n",
      "\r\n",
      "No VM guests are running outdated hypervisor (qemu) binaries on this host.\r\n"
     ]
    }
   ],
   "source": [
    "!apt install slurm-wlm -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFUVddWILGUA"
   },
   "source": [
    "You can use the `scontrol version` command to find out the installed SLURM version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.208502Z",
     "iopub.status.busy": "2025-11-24T08:11:12.208297Z",
     "iopub.status.idle": "2025-11-24T08:11:12.352052Z",
     "shell.execute_reply": "2025-11-24T08:11:12.351319Z"
    },
    "id": "ad27e1d6",
    "outputId": "0f491202-5627-4dc1-8559-1b05e0fccae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scontrol: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host\r\n",
      "scontrol: error: fetch_config: DNS SRV lookup failed\r\n",
      "scontrol: error: _establish_config_source: failed to fetch config\r\n",
      "scontrol: fatal: Could not establish a configuration source\r\n"
     ]
    }
   ],
   "source": [
    "!scontrol version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brQkWtmMi786"
   },
   "source": [
    "## üìù Side Note: What is `slurm-wlm`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUXFHKA34Us5"
   },
   "source": [
    "`slurm-wlm` is the Debian package for SLURM and it is an unofficial distribution from **SchedMD**'s perspective (SchedMD is the company that develops and maintains the open-source Slurm Workload Manager).\n",
    "\n",
    "According to the [Slurm Quick Start Administrator Guide](https://slurm.schedmd.com/quickstart_admin.html#quick_start), SchedMD explicitly notes:\n",
    "\n",
    "> **NOTE**: Some Linux distributions may have unofficial Slurm packages available in software repositories. SchedMD does not maintain or recommend these packages.\n",
    "\n",
    "Some of the reasons why SchedMD does not recommend inofficial builds might be:\n",
    "\n",
    "1. **SchedMD Does Not Maintain It**: The `slurm-wlm` package is maintained by the Debian community, not by SchedMD, the official developers of Slurm. Debian maintainers build and package Slurm for inclusion in their repositories, which may include modifications or configurations that differ from SchedMD's official releases.\n",
    "\n",
    "2. **Potential for Issues**: Unofficial packages may not always align with SchedMD's latest recommendations, configurations, or patches. This can lead to compatibility issues, missing features, or differences in behavior compared to SchedMD's official builds.\n",
    "\n",
    "3. **SchedMD's Recommendation**: SchedMD recommends building Slurm from source or using RPM/DEB packages built directly from their official tarballs (e.g., using `rpmbuild` or `debuild` as described in the guide). This ensures full control over the build process, dependencies, and configuration, tailored to the user's specific cluster needs.\n",
    "\n",
    "Despite SchedMD's recommendation against unofficial packages, users might choose Debian's `slurm-wlm` for convenience, especially in environments already integrated with Debian's package management system (`apt`). Benefits include:\n",
    "\n",
    "- **Ease of Installation**: Installing `slurm-wlm` via `apt` is simpler than building from source or creating custom packages.\n",
    "- **Dependency Management**: Debian's package manager automatically handles dependencies like `munge`, `mysql`, or other required libraries.\n",
    "- **System Integration**: The package is configured to work with Debian's conventions (e.g., systemd services, file paths like `/etc/slurm/` for configuration).\n",
    "\n",
    "However, users should be cautious:\n",
    "\n",
    "- **Version Lag**: Debian's `sid` repository may not always have the latest Slurm version. For example, as of October 12, 2025, `slurm-wlm` is at version `24.11.5-4`, which is recent but may lag behind SchedMD's latest releases.\n",
    "- **Customizations**: Debian's package may include patches or configurations not endorsed by SchedMD, potentially affecting behavior.\n",
    "- **Support**: Issues with Debian's package would need to be addressed through Debian's bug tracker rather than SchedMD's support channels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31Q0HgWMK19o"
   },
   "source": [
    "## üìù Side Note: A Brief History of SLURM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vErIxs2gPYP"
   },
   "source": [
    "Slurm was first developed in 2001 at **Lawrence Livermore National Laboratory (LLNL)** to manage large Linux clusters for high-performance computing (HPC). The first formal publication of Slurm appeared in a 2003 paper by Yoo, A.B., Jette, M.A., and Grondona, M., titled \"SLURM: Simple Linux Utility for Resource Management,\" presented at the Workshop on Job Scheduling Strategies for Parallel Processing (published in Lecture Notes in Computer Science, pp. 44‚Äì60, Springer Berlin Heidelberg). This paper introduced Slurm‚Äôs design principles, emphasizing its lightweight architecture and adaptability and it is available at [https://www.osti.gov/servlets/purl/15002533](https://www.osti.gov/servlets/purl/15002533).\n",
    "\n",
    "Slurm was designed as a lightweight, scalable alternative to existing resource managers. Over the years, SLURM gained popularity in the HPC community, with significant adoption by supercomputing centers. Key milestones include the introduction of the REST API in 2020 and support for JWT authentication in 2023.\n",
    "\n",
    "In terms of scheduling, SLURM has evolved from initially only supporting FIFO to:\n",
    "- **Multifactor Priority Scheduling**, where multiple factors such as quality of service, age, size, _fairshare_, are taken into account when prioritizing jobs\n",
    "- **Backfill Scheduling**, allowing smaller, shorter jobs to ‚Äúfill in‚Äù gaps in the schedule while waiting for larger jobs to acquire sufficient resources\n",
    "- **Preemption**, where higher-priority jobs can interrupt or suspend lower-priority jobs to access resources immediately\n",
    "- **Advanced Resource Allocation**: SLURM can allocate exactly the resources a job needs‚ÄîCPUs, GPUs, memory, licenses, or even specific nodes‚Äîdown to the socket or core level\n",
    "- **Burst Buffer Support**: fast intermediate storage (e.g., NVMe SSDs) placed between RAM and parallel filesystem to speed up I/O-heavy jobs without flooding slow storage\n",
    "- **Cloud & Elastic Computing**: automatically spin up/down cloud nodes (AWS, Azure, GCP) when on-prem resources are full\n",
    "- **Container Support**: run jobs inside Docker, Singularity/Apptainer, or Podman containers directly via SLURM to ensures reproducible, portable, secure software environments\n",
    "\n",
    "Today, SLURM powers some of the world's largest supercomputers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFtQ9QQgj98S"
   },
   "source": [
    "## üìù Side Note: Debian's `sid` and SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADJNkIxFkBbH"
   },
   "source": [
    "Debian's versioning includes **stable** (e.g., `bookworm`), **testing** (e.g., `trixie`), and **unstable** (`sid`) branches. The `sid` branch, named after the mischievous character Sid from Toy Story (1995, Pixar Animation Studios), who breaks toys and creates chaos, reflects its role as Debian's cutting-edge, unstable repository where packages are continuously updated. As noted in Debian's documentation, `sid` is a development playground, prone to breakages but offering the latest software versions, like `slurm-wlm` version `24.11.5-4` as of October 2025.\n",
    "\n",
    "Users might choose `slurm-wlm` from `sid` for its recent SLURM features, such as enhanced GPU autodetection (`AutoDetect=nvml` for NVIDIA GPUs) or REST API improvements (`slurmrestd`), which may not yet be in `bookworm` (e.g., `23.02.x`). Its integration with Debian‚Äôs `apt` simplifies installation and dependency management (e.g., `munge`, `mysql`). However, `sid`‚Äôs instability‚Äîakin to Sid‚Äôs destructive antics in Toy Story‚Äîmakes it risky for production HPC clusters, as updates can introduce bugs or dependency conflicts. For testing or research environments needing the latest SLURM capabilities, `sid` is appealing, but SchedMD recommends building from source for reliability and official support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sml8t6rVM17l"
   },
   "source": [
    "## üìù Side Note: Nerdy Names, Serious Systems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ipvf135-L1Wq"
   },
   "source": [
    "While SLURM stands for Simple Linux Utility for Resource Management it also nods to *Slurm*, the soft drink in *Futurama*.\n",
    "\n",
    "I notice more and more how deeply tech culture is shaped by the tastes and humor of a specific group ‚Äî mostly young, male ‚Äúnerds.‚Äù Debian versions named after *Toy Story* characters, SLURM taking its name from a beverage in *Futurama* ‚Äî these choices aren‚Äôt random. They reveal a shared subculture that has long defined open-source and DevOps communities.\n",
    "\n",
    "What started as playful references among enthusiasts has become a kind of tradition ‚Äî a way of signaling identity and belonging. The same spirit shows up in projects like **Borg** (_Star Trek_) or **Python** (_Monty Python‚Äôs Flying Circus_). It‚Äôs a mix of wit, nostalgia, and a sense of ‚Äúif you get the joke, you‚Äôre one of us.‚Äù\n",
    "\n",
    "It encodes a certain kind of taste and belonging: if you recognize *Toy Story*, *Futurama*, *Star Wars*, or *Monty Python* jokes, you‚Äôre in the club. If not, you‚Äôre subtly reminded that the culture wasn‚Äôt built with you in mind. It‚Äôs not malicious, but it is a reflection of a narrow demographic shaping the collective tone of open-source and DevOps culture. And that tone often persists even as the field itself has become more diverse and mature.\n",
    "\n",
    "There‚Äôs an interesting contrast here: these projects embody serious technical excellence, yet their cultural expression is stuck in a kind of perpetual adolescence ‚Äî like an in-joke from a college dorm that somehow became global infrastructure.\n",
    "\n",
    "This tendency, however, is mostly a relic of the early days of computer science up through the 1990s, when the field was dominated by a small, highly homogeneous group of enthusiasts steeped in science fiction, comics, and arcade culture. Modern technologies increasingly break away from this ‚Äúnerd comics‚Äù culture, opting instead for names that are descriptive, abstract, or evocative. Examples include *Terraform*, *Docker*, *Kubernetes*, *Airflow*, *Figma*, *Notion*, and *Snowflake* ‚Äî names that signal function, creativity, or metaphor rather than relying on insider pop-culture knowledge.\n",
    "\n",
    "Perhaps what could be wished for is simply more freedom to break away from that established mold. Tech doesn‚Äôt have to lose its sense of humor to grow up a little. It can remain creative and irreverent, while exploring names, metaphors, and references that reflect the wider, richer world of ideas around it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhhgV7kNYT7c"
   },
   "source": [
    "## üöÄ Configuration\n",
    "\n",
    "Configuration instructions are provided in `/usr/share/doc/slurmctld/README.Debian`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.354969Z",
     "iopub.status.busy": "2025-11-24T08:11:12.354770Z",
     "iopub.status.idle": "2025-11-24T08:11:12.467135Z",
     "shell.execute_reply": "2025-11-24T08:11:12.466353Z"
    },
    "id": "tVdSILtfYJGk",
    "outputId": "242246e7-3e9a-4b9c-f159-0ae5412fcfb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Instructions\r\n",
      "==========================\r\n",
      "In order to use SLURM you need a proper configuration file for your\r\n",
      "cluster that need to be stored under /etc/slurm/slurm.conf on every\r\n",
      "node. You can point your browser to\r\n",
      "file:///usr/share/doc/slurmctld/slurm-wlm-configurator.html for an\r\n",
      "automatic configuration tool. Please leave red fields untouched and\r\n",
      "change green field to fit your cluster configuration.\r\n",
      "\r\n",
      "You can also find a simple sample configuration that provides a\r\n",
      "control machine to run the Slurm's central management daemon and\r\n",
      "a single node for job execution under\r\n",
      "/usr/share/doc/slurmctld/examples/slurm.conf.simple.gz\r\n"
     ]
    }
   ],
   "source": [
    "!cat /usr/share/doc/slurmctld/README.Debian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDJ51P8xVhOK"
   },
   "source": [
    "We are going to create a file `slurm.conf`.\n",
    "\n",
    "For convenience, create a symbolic link to the folder `/etc/slurm` so that the file can be opened from the left pane in Google Colab's Jupyterhub interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.469598Z",
     "iopub.status.busy": "2025-11-24T08:11:12.469396Z",
     "iopub.status.idle": "2025-11-24T08:11:12.581193Z",
     "shell.execute_reply": "2025-11-24T08:11:12.580264Z"
    },
    "id": "vsmGSDV_YcNS"
   },
   "outputs": [],
   "source": [
    "!ln -s /etc/slurm ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHWqyIilbDmK"
   },
   "source": [
    "4 CPUs, 7923 MB RAM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.584063Z",
     "iopub.status.busy": "2025-11-24T08:11:12.583678Z",
     "iopub.status.idle": "2025-11-24T08:11:12.588781Z",
     "shell.execute_reply": "2025-11-24T08:11:12.588090Z"
    },
    "id": "-wlRLDmLVPNj",
    "outputId": "10821dea-1a3f-4a0e-b68f-e7c8c706ec42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /etc/slurm/slurm.conf\n"
     ]
    }
   ],
   "source": [
    "%%writefile /etc/slurm/slurm.conf\n",
    "# Minimal slurm.conf for single-node testing\n",
    "ClusterName=mylocalcluster\n",
    "SlurmctldHost=localhost\n",
    "AuthType=auth/munge\n",
    "MpiDefault=none\n",
    "ProctrackType=proctrack/linuxproc\n",
    "ReturnToService=2\n",
    "SlurmctldPidFile=/var/run/slurmctld.pid\n",
    "SlurmctldPort=6817\n",
    "SlurmdPidFile=/var/run/slurmd.pid\n",
    "SlurmdPort=6818\n",
    "StateSaveLocation=/var/spool/slurmctld\n",
    "SlurmdSpoolDir=/var/spool/slurmd\n",
    "SlurmUser=slurm\n",
    "SlurmdLogFile=/var/log/slurmd.log\n",
    "SlurmctldLogFile=/var/log/slurmctld.log\n",
    "# Node and partition configuration\n",
    "NodeName=localhost CPUs=2 RealMemory=7923 State=UNKNOWN\n",
    "PartitionName=LocalQ Nodes=localhost Default=YES MaxTime=INFINITE State=UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWB0pjcMWzi0"
   },
   "source": [
    "Verify your config: NodeName, ControlMachine, and PartitionName.Nodes must match either `localhost` or `hostname -s`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhJQeLeT99Tz"
   },
   "source": [
    "## üìù Configure using `slurm-wlm-configurator.html`\n",
    "\n",
    "Instead of editing the configuration file `slurm.conf` you could also start a minimal Web app. This is an overkill for the current demonstration but it might be interesting to see all possible SLURM configuration parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXkH_FY1CtFl"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krQCXb9HMwil"
   },
   "source": [
    "Begin by creating a minimal Flask Web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.591310Z",
     "iopub.status.busy": "2025-11-24T08:11:12.590895Z",
     "iopub.status.idle": "2025-11-24T08:11:12.594750Z",
     "shell.execute_reply": "2025-11-24T08:11:12.594177Z"
    },
    "id": "zL87RRKqt2Ot",
    "outputId": "04b0b042-4be4-47df-8cea-73f6fb10c099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_flask.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_flask.py\n",
    "from flask import Flask, Response\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def serve_configurator():\n",
    "   try:\n",
    "       with open('/usr/share/doc/slurmctld/slurm-wlm-configurator.html', 'r') as f:\n",
    "           html_content = f.read()\n",
    "       return Response(html_content, mimetype='text/html')\n",
    "   except FileNotFoundError:\n",
    "       return \"Error: slurm-wlm-configurator.html not found\", 404\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.596754Z",
     "iopub.status.busy": "2025-11-24T08:11:12.596439Z",
     "iopub.status.idle": "2025-11-24T08:11:12.606070Z",
     "shell.execute_reply": "2025-11-24T08:11:12.605252Z"
    },
    "id": "pmr_NqNSt3VS"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "\n",
    "# Check if the process is running and terminate it\n",
    "if 'process' in locals() and process.poll() is None:\n",
    "    print(\"Terminating existing Flask process...\")\n",
    "    process.terminate()\n",
    "\n",
    "with open('flask.out', \"w\") as stdout_file, open('flask.err', \"w\") as stderr_file:\n",
    "    process = subprocess.Popen(\n",
    "        [\"python\", \"run_flask.py\"],\n",
    "        stdout=stdout_file,\n",
    "        stderr=stderr_file,\n",
    "        preexec_fn=os.setsid  # Start the process in a new session\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX4Dj9P5Cwbx"
   },
   "source": [
    "Serve the Web app through `output` (only works if in Google Colab). Click on the link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.608779Z",
     "iopub.status.busy": "2025-11-24T08:11:12.608563Z",
     "iopub.status.idle": "2025-11-24T08:11:12.612447Z",
     "shell.execute_reply": "2025-11-24T08:11:12.611672Z"
    },
    "id": "MdU_M04muIQ0",
    "outputId": "38787b18-0299-46e1-bb88-73a4e2ee82a7"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# true if running on Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "  from google.colab import output\n",
    "  output.serve_kernel_port_as_window(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.614496Z",
     "iopub.status.busy": "2025-11-24T08:11:12.614289Z",
     "iopub.status.idle": "2025-11-24T08:11:12.725623Z",
     "shell.execute_reply": "2025-11-24T08:11:12.724894Z"
    },
    "id": "0EsfKH2VW2L4",
    "outputId": "2772f9bb-7c40-4a86-c87a-b6f6809ecb93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runnervmg1sw1\r\n"
     ]
    }
   ],
   "source": [
    "!hostname -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d8C0ay3Xa-d"
   },
   "source": [
    "## üöÄ Generate a `munge` key\n",
    "\n",
    "MUNGE stands for **M**ac-based **U**ser **N**ame **G**roup **E**xpiration and it is a lightweight, high-performance authentication system used by SLURM to securely verify user identity (UID/GID) and message integrity across cluster nodes using a shared symmetric key and time-limited credentials. It ensures fast, trusted communication between SLURM daemons and clients with minimal overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvm489ZVbj1r"
   },
   "source": [
    "Generate a secure, random 1024-byte shared key for MUNGE authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.728328Z",
     "iopub.status.busy": "2025-11-24T08:11:12.728119Z",
     "iopub.status.idle": "2025-11-24T08:11:12.761299Z",
     "shell.execute_reply": "2025-11-24T08:11:12.760537Z"
    },
    "id": "2HPJoAE5Xpyy"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo dd if=/dev/urandom of=/etc/munge/munge.key bs=1 count=1024 >/dev/null 2>&1\n",
    "sudo chown munge:munge /etc/munge/munge.key\n",
    "sudo chmod 400 /etc/munge/munge.key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgqo9xAZXxYS"
   },
   "source": [
    "## üöÄ Create Spool Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.764043Z",
     "iopub.status.busy": "2025-11-24T08:11:12.763586Z",
     "iopub.status.idle": "2025-11-24T08:11:12.802321Z",
     "shell.execute_reply": "2025-11-24T08:11:12.801358Z"
    },
    "id": "VhO4SsqMX0yP"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo mkdir -p /var/spool/slurmctld /var/spool/slurmd /var/lib/munge\n",
    "sudo chown slurm:slurm /var/spool/slurm{ctld,d} /var/lib/munge\n",
    "sudo chown munge:munge /var/lib/munge\n",
    "sudo chmod 755 /var/spool/slurm* /var/lib/munge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra4_XsQsncaY"
   },
   "source": [
    "> ### üìå Recap: installation\n",
    "> - On Ubuntu, install the unofficial Debian package for SLURM with the command `apt install slurm-wlm -y`\n",
    "> - A minimal configuration requires creating a `slurm.conf` file, a `munge` key, and spool directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFMWSBKBX7Yl"
   },
   "source": [
    "## üöÄ Start the Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufPA8L4hqQ7L"
   },
   "source": [
    "Skip the next step if you are launching the services for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:12.805381Z",
     "iopub.status.busy": "2025-11-24T08:11:12.804916Z",
     "iopub.status.idle": "2025-11-24T08:11:15.145381Z",
     "shell.execute_reply": "2025-11-24T08:11:15.144479Z"
    },
    "id": "CAbDbtEWX_kP",
    "outputId": "30eef4a2-c404-45cf-948b-6be827a5380f"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo service munge stop\n",
    "sudo service slurmctld stop\n",
    "sudo service slurmd stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:15.148145Z",
     "iopub.status.busy": "2025-11-24T08:11:15.147770Z",
     "iopub.status.idle": "2025-11-24T08:11:17.514563Z",
     "shell.execute_reply": "2025-11-24T08:11:17.513697Z"
    },
    "id": "FXZ71G39ZKke",
    "outputId": "2c37045e-143f-4c78-bde1-cdd9009b6600"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo service munge start\n",
    "sudo service slurmctld start\n",
    "sudo service slurmd start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92wZzJmSfK35"
   },
   "source": [
    "## üöÄ Verify Cluster Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:17.517369Z",
     "iopub.status.busy": "2025-11-24T08:11:17.516907Z",
     "iopub.status.idle": "2025-11-24T08:11:17.632468Z",
     "shell.execute_reply": "2025-11-24T08:11:17.631558Z"
    },
    "id": "iWWFjgBTfMal",
    "outputId": "6e62496a-493c-4d56-f1f4-895985180408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\r\n",
      "LocalQ*      up   infinite      1   idle localhost\r\n"
     ]
    }
   ],
   "source": [
    "!sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij97YCdMNLiO"
   },
   "source": [
    "You should see something like\n",
    "```\n",
    "PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
    "LocalQ*      up   infinite      1   idle localhost\n",
    "```\n",
    "\n",
    "This is a 1-node cluster with no time limit for jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIXkkbNAfPSj"
   },
   "source": [
    "If the node is not idle, set it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:17.635595Z",
     "iopub.status.busy": "2025-11-24T08:11:17.635129Z",
     "iopub.status.idle": "2025-11-24T08:11:17.756934Z",
     "shell.execute_reply": "2025-11-24T08:11:17.756140Z"
    },
    "id": "kMpX-uFQfadO"
   },
   "outputs": [],
   "source": [
    "!sudo scontrol update NodeName=6d91971d1d4a State=IDLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNeusBTLcqve"
   },
   "source": [
    "## üìù Useful Commands for Debugging\n",
    "\n",
    "To look for errors you can use:\n",
    "\n",
    "- `tail /var/log/slurmctld.log` to view the end of the `slurmctld` log file.\n",
    "- `grep \"error\" /var/log/slurmctld.log` to search for specific terms like \"error\" in the log file.\n",
    "- `sudo -u slurm /usr/sbin/slurmctld -D -vvv` for streaming output to the console\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:17.759675Z",
     "iopub.status.busy": "2025-11-24T08:11:17.759451Z",
     "iopub.status.idle": "2025-11-24T08:11:17.871739Z",
     "shell.execute_reply": "2025-11-24T08:11:17.870861Z"
    },
    "id": "mkg0m1F5aIoy",
    "outputId": "d9bddad2-a551-41aa-c8c7-28f53760031e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grep: /var/log/slurmctld.log: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"error\" /var/log/slurmctld.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOevZO30pBK4"
   },
   "source": [
    "> ## üìå Recap: start SLURM\n",
    "> - Three services need to be started: `munge`, `slurmctld`, and `slurmd`.\n",
    "> - Use `sinfo` to verify the cluster status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua-nBgvmsJpA"
   },
   "source": [
    "## üöÄ Run a simple job\n",
    "\n",
    "To run a SLURM job, you generally embed _SLURM directives_ inside a shell script. This script tells SLURM what resources you need and what commands to execute.\n",
    "\n",
    "The script must start with #!/bin/bash or another valid shell.\n",
    "\n",
    "All SLURM directives start with `#SBATCH` and must appear at the top of the script before any commands. For instance the following directives\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --partition=LocalQ\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=100M\n",
    "```\n",
    "tell SLURM:\n",
    "- to run the job in partition (queue) `LocalQ` (we chose this name in the configuration file);\n",
    "- to run one task (one single process) with $2$ CPU cores for each task;\n",
    "- to request $100$ megabytes of RAM‚ÄîSLURM will reserve this amount and prevent your job from exceeding it. Depending on how memory constraints are configured, if your program uses more memory than requested, it may be terminated.\n",
    "\n",
    "After the `#SBATCH` directives, you can write normal shell commands.\n",
    "\n",
    "‚ö†Ô∏è Be careful not insert blank lines between the shebang (`#!/bin/bash`) and the directives (`#SBATCH`) otherwise SLURM will ignore them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7a4-uIH9ODT"
   },
   "source": [
    "This is a bash script that computes the sum of the first $100$ numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:17.874640Z",
     "iopub.status.busy": "2025-11-24T08:11:17.874419Z",
     "iopub.status.idle": "2025-11-24T08:11:17.879281Z",
     "shell.execute_reply": "2025-11-24T08:11:17.878558Z"
    },
    "id": "Mqr1tRXvkd5x",
    "outputId": "dc07d2fa-71f5-4a3d-8459-d63049f9efd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simple_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_job.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --partition=LocalQ\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=100M\n",
    "\n",
    "echo \"Job started on $(hostname) at $(date)\"\n",
    "echo \"Running on node: $SLURM_NODELIST\"\n",
    "echo \"Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Calculating sum of numbers 1 to 100...\"\n",
    "sum=0\n",
    "for i in {1..100}; do\n",
    "    sum=$((sum + i))\n",
    "done\n",
    "echo \"Sum: $sum\"\n",
    "sleep 5\n",
    "echo \"Job finished at $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:17.881449Z",
     "iopub.status.busy": "2025-11-24T08:11:17.881073Z",
     "iopub.status.idle": "2025-11-24T08:11:22.898245Z",
     "shell.execute_reply": "2025-11-24T08:11:22.897364Z"
    },
    "id": "8RGthhyJk-cI",
    "outputId": "6939621d-3b83-460e-f882-855c70b2657a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x simple_job.sh\n",
    "sbatch simple_job.sh\n",
    "sleep 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:22.900946Z",
     "iopub.status.busy": "2025-11-24T08:11:22.900551Z",
     "iopub.status.idle": "2025-11-24T08:11:23.013253Z",
     "shell.execute_reply": "2025-11-24T08:11:23.012267Z"
    },
    "id": "r_M2u0yJlQAI",
    "outputId": "e803d07a-c1c0-42bc-97b0-cadcf7945287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'slurm-*.out': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls slurm-*.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.015991Z",
     "iopub.status.busy": "2025-11-24T08:11:23.015769Z",
     "iopub.status.idle": "2025-11-24T08:11:23.128049Z",
     "shell.execute_reply": "2025-11-24T08:11:23.127255Z"
    },
    "id": "3BNaJMn8lTOs",
    "outputId": "2a02dede-83b9-42ff-ed68-cacbdc6384d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: slurm-1.out: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat slurm-1.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kdr7QnootMiw"
   },
   "source": [
    "Check if the result is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.130591Z",
     "iopub.status.busy": "2025-11-24T08:11:23.130368Z",
     "iopub.status.idle": "2025-11-24T08:11:23.137624Z",
     "shell.execute_reply": "2025-11-24T08:11:23.137076Z"
    },
    "id": "Zy9TZElhs__A",
    "outputId": "37efc090-e685-4695-bb7d-0e7eb246ac90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*101/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DAjlH9ltWXj"
   },
   "source": [
    "## üöÄ Did the Job Run in Parallel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.139527Z",
     "iopub.status.busy": "2025-11-24T08:11:23.139336Z",
     "iopub.status.idle": "2025-11-24T08:11:23.253557Z",
     "shell.execute_reply": "2025-11-24T08:11:23.252769Z"
    },
    "id": "vbfx_M89t89I",
    "outputId": "176b8aed-10ca-4414-9b8b-831a3dbf4c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId=1 JobName=simple_job.sh\r\n",
      "   UserId=root(0) GroupId=root(0) MCS_label=N/A\r\n",
      "   Priority=1 Nice=0 Account=(null) QOS=(null)\r\n",
      "   JobState=PENDING Reason=InvalidAccount Dependency=(null)\r\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\r\n",
      "   RunTime=00:00:00 TimeLimit=UNLIMITED TimeMin=N/A\r\n",
      "   SubmitTime=2025-11-24T08:11:17 EligibleTime=2025-11-24T08:11:17\r\n",
      "   AccrueTime=2025-11-24T08:11:17\r\n",
      "   StartTime=Unknown EndTime=Unknown Deadline=N/A\r\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-24T08:11:19 Scheduler=Main\r\n",
      "   Partition=LocalQ AllocNode:Sid=runnervmg1sw1:2685\r\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\r\n",
      "   NodeList=\r\n",
      "   NumNodes=1 NumCPUs=2 NumTasks=1 CPUs/Task=2 ReqB:S:C:T=0:0:*:*\r\n",
      "   ReqTRES=cpu=2,mem=100M,node=1,billing=2\r\n",
      "   AllocTRES=(null)\r\n",
      "   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\r\n",
      "   MinCPUsNode=2 MinMemoryNode=100M MinTmpDiskNode=0\r\n",
      "   Features=(null) DelayBoot=00:00:00\r\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\r\n",
      "   Command=/home/runner/work/big_data/big_data/simple_job.sh\r\n",
      "   WorkDir=/home/runner/work/big_data/big_data\r\n",
      "   StdErr=/home/runner/work/big_data/big_data/slurm-1.out\r\n",
      "   StdIn=/dev/null\r\n",
      "   StdOut=/home/runner/work/big_data/big_data/slurm-1.out\r\n",
      "   Power=\r\n",
      "   TresPerTask=cpu:2\r\n",
      "   \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!scontrol show job 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G19ZE50zuZbt"
   },
   "source": [
    "The line\n",
    "```\n",
    "NumNodes=1 NumCPUs=2 NumTasks=1 CPUs/Task=2 ...\n",
    "```\n",
    "confirms that SLURM reserved 2 CPUs for our job.\n",
    "\n",
    "But this doesn't mean that the job used the two CPUs for parallel computation since our script `simple_job.sh` is a sequential Bash loop (`for i in {1..100}`) that runs on a single process/thread.\n",
    "\n",
    "The option `--cpus-per-task=2` means that SLURM allocates 2 CPUs to the job and that other jobs can‚Äôt use them, but the script‚Äôs computation remains single-threaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXpc7Ko5cH4-"
   },
   "source": [
    "> ## üìå Recap: SLURM doesn't parallelize your code for you\n",
    "> SLURM just hooks you up with resources like CPUs or machines. If your program‚Äôs single-threaded, it‚Äôll stick to one CPU unless you make it parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPWDC-e1OXVP"
   },
   "source": [
    "**Note:** The `scontrol show job` command primarily shows information about jobs that are currently running or have recently completed and are still held in SLURM's internal state. This information is not retained indefinitely.\n",
    "\n",
    "For long-term retention of job information, SLURM uses an accounting database that needs to be installed extra and can be queried with `sacct`). The retention period for job information in the accounting database is determined by the SLURM accounting configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH60mvkDzzFk"
   },
   "source": [
    "## üöÄ  Single-task parallel Python with `multiprocessing` and `--cpus-per-task`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNiHqJACv4ZO"
   },
   "source": [
    "Let us modify the script so that it runs in parallel on the two CPUs. In order to achieve this, let us use Python's `multiprocessing` library. Note that we still need to wrap our code inside a shell script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.256386Z",
     "iopub.status.busy": "2025-11-24T08:11:23.256184Z",
     "iopub.status.idle": "2025-11-24T08:11:23.261329Z",
     "shell.execute_reply": "2025-11-24T08:11:23.260652Z"
    },
    "id": "NweDRLhSv8vu",
    "outputId": "6d122e19-b49d-42a1-e54f-7be552da9fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simple_job_parallel.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_job_parallel.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --partition=LocalQ\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=100M\n",
    "\n",
    "echo \"Job started on $(hostname) at $(date)\"\n",
    "echo \"Running on node: $SLURM_NODELIST\"\n",
    "echo \"Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Calculating sum of numbers 1 to 100 in parallel with Python...\"\n",
    "\n",
    "python3 -c \"\n",
    "from multiprocessing import Pool\n",
    "def add(x): return x\n",
    "with Pool(processes=2) as pool:\n",
    "    result = sum(pool.map(add, range(1, 101)))\n",
    "print(f'Sum: {result}')\n",
    "\"\n",
    "\n",
    "sleep 10\n",
    "echo \"Job finished at $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.263324Z",
     "iopub.status.busy": "2025-11-24T08:11:23.262984Z",
     "iopub.status.idle": "2025-11-24T08:11:23.281117Z",
     "shell.execute_reply": "2025-11-24T08:11:23.280319Z"
    },
    "id": "8RcwsrF_vn8n"
   },
   "outputs": [],
   "source": [
    "%%bash --out id\n",
    "sbatch simple_job_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.283565Z",
     "iopub.status.busy": "2025-11-24T08:11:23.283349Z",
     "iopub.status.idle": "2025-11-24T08:11:23.394632Z",
     "shell.execute_reply": "2025-11-24T08:11:23.393710Z"
    },
    "id": "xjp6H6rF9wq8",
    "outputId": "1d62f0b8-c99e-491f-ab98-02007c011d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2\r\n"
     ]
    }
   ],
   "source": [
    "!echo {id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.397508Z",
     "iopub.status.busy": "2025-11-24T08:11:23.397034Z",
     "iopub.status.idle": "2025-11-24T08:11:23.400630Z",
     "shell.execute_reply": "2025-11-24T08:11:23.400066Z"
    },
    "id": "11ZA-QSy9xWZ"
   },
   "outputs": [],
   "source": [
    "JOB_ID = id.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.402918Z",
     "iopub.status.busy": "2025-11-24T08:11:23.402518Z",
     "iopub.status.idle": "2025-11-24T08:11:23.514304Z",
     "shell.execute_reply": "2025-11-24T08:11:23.513490Z"
    },
    "id": "YUno8Yd2wqZ8",
    "outputId": "0db55470-d358-49eb-dab7-afd0bdb4255c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: slurm-2.out: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat slurm-{JOB_ID}.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhqUzxy-3NMW"
   },
   "source": [
    "Let us introduce some logging to view the parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.516927Z",
     "iopub.status.busy": "2025-11-24T08:11:23.516716Z",
     "iopub.status.idle": "2025-11-24T08:11:23.521783Z",
     "shell.execute_reply": "2025-11-24T08:11:23.521180Z"
    },
    "id": "DggIOqU23T0O",
    "outputId": "c8f4212d-28a9-4529-912c-a03851ba313d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simple_job_parallel.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_job_parallel.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=\"Run in Parallel\"  # name of the job\n",
    "#SBATCH --partition=LocalQ\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=100M\n",
    "#SBATCH --time=00:02:00               # HH:MM:SS format\n",
    "\n",
    "# Ensure psutil is installed\n",
    "if ! python3 -c \"import psutil\" 2>/dev/null; then\n",
    "    sudo apt update && sudo apt install -y python3-psutil\n",
    "fi\n",
    "\n",
    "echo \"Job started on $(hostname) at $(date)\"\n",
    "echo \"Running on node: $SLURM_NODELIST\"\n",
    "echo \"Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Calculating sum of numbers from 1 to 100 in parallel with Python...\"\n",
    "\n",
    "python3 -c \"\n",
    "import multiprocessing as mp\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "def add(x):\n",
    "    # Log PID and CPU affinity\n",
    "    process = psutil.Process()\n",
    "    cpu_affinity = process.cpu_affinity()\n",
    "    start_time = time.ctime(process.create_time())\n",
    "    print(f'Process PID={os.getpid()}, CPU affinity={cpu_affinity}, Start time={start_time}, x={x}')\n",
    "    return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with mp.Pool(processes=2) as pool:\n",
    "        result = sum(pool.map(add, range(1, 101)))\n",
    "    print(f'Sum of numbers: {result}')\n",
    "\"\n",
    "\n",
    "sleep 10\n",
    "echo \"Job finished at $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.524033Z",
     "iopub.status.busy": "2025-11-24T08:11:23.523595Z",
     "iopub.status.idle": "2025-11-24T08:11:23.536714Z",
     "shell.execute_reply": "2025-11-24T08:11:23.535969Z"
    },
    "id": "sybAWfLO3m7k"
   },
   "outputs": [],
   "source": [
    "%%bash --out id\n",
    "sbatch simple_job_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.539289Z",
     "iopub.status.busy": "2025-11-24T08:11:23.538835Z",
     "iopub.status.idle": "2025-11-24T08:11:23.649772Z",
     "shell.execute_reply": "2025-11-24T08:11:23.649059Z"
    },
    "id": "86D15H5s3oOX",
    "outputId": "df30b64e-ec3d-4a4d-8d6d-29f8cd0399ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3\r\n"
     ]
    }
   ],
   "source": [
    "!echo {id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO0sv3_sxmam"
   },
   "source": [
    "**Note:** the number of processes (defined in `Pool(processes=2)`) should not exceed the CPUs reserved in SLURM (`--cpus-per-task=2`), otherwise some processes might have to wait while the maximum $2$ CPUs available simultaneosly are busy. Running more parallel processes than the number of CPUs reserved (via `--cpus-per-task`) is called _oversubscription_. The job might still complete if there is enough available memory, but it will be slowed down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.652577Z",
     "iopub.status.busy": "2025-11-24T08:11:23.652164Z",
     "iopub.status.idle": "2025-11-24T08:11:23.655746Z",
     "shell.execute_reply": "2025-11-24T08:11:23.655051Z"
    },
    "id": "zbE1yMeh8hXE"
   },
   "outputs": [],
   "source": [
    "JOB_ID = id.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:11:23.657708Z",
     "iopub.status.busy": "2025-11-24T08:11:23.657514Z",
     "iopub.status.idle": "2025-11-24T08:12:59.048797Z",
     "shell.execute_reply": "2025-11-24T08:12:59.047877Z"
    },
    "id": "lV-5kRp68P-5",
    "outputId": "86d19140-0678-49b6-ea3b-8d719cc20b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root  R       0:02      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 3 to finish...\n",
      "                 3    LocalQ Run in P     root  R       0:07      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 3 finished.\n",
      "Job started on runnervmg1sw1 at Mon Nov 24 08:12:46 UTC 2025\r\n",
      "Running on node: localhost\r\n",
      "Job ID: 3\r\n",
      "Calculating sum of numbers from 1 to 100 in parallel with Python...\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=14\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=15\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=16\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=17\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=18\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=19\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=20\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=21\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=22\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=23\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=24\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=25\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=26\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=40\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=41\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=42\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=43\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=44\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=45\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=46\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=47\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=48\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=49\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=50\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=51\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=52\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=66\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=67\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=68\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=69\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=70\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=71\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=72\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=73\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=74\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=75\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=76\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=77\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=78\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=92\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=93\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=94\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=95\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=96\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=97\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=98\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=99\r\n",
      "Process PID=4106, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=100\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=1\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=2\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=3\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=4\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=5\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=6\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=7\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=8\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=9\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=10\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=11\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=12\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=13\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=27\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=28\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=29\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=30\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=31\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=32\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=33\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=34\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=35\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=36\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=37\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=38\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=39\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=53\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=54\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=55\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=56\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=57\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=58\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=59\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=60\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=61\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=62\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=63\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=64\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=65\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=79\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=80\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=81\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=82\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=83\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=84\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=85\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=86\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=87\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=88\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=89\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=90\r\n",
      "Process PID=4105, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:12:46 2025, x=91\r\n",
      "Sum of numbers: 5050\r\n",
      "Job finished at Mon Nov 24 08:12:56 UTC 2025\r\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Wait for the job to finish\n",
    "while True:\n",
    "    result = !squeue -j {JOB_ID} -h\n",
    "    if not result:  # squeue returns empty if job is not in queue\n",
    "        print(f\"Job {JOB_ID} finished.\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Waiting for job {JOB_ID} to finish...\")\n",
    "        print(\"\\n\".join(result))\n",
    "        time.sleep(5) # Wait for 5 seconds before checking again\n",
    "\n",
    "# After the job is finished, you can view the output files\n",
    "!cat slurm-{JOB_ID}.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zs60Rso4r3Z"
   },
   "source": [
    "We can now see that two processes were spawned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.051443Z",
     "iopub.status.busy": "2025-11-24T08:12:59.051223Z",
     "iopub.status.idle": "2025-11-24T08:12:59.165565Z",
     "shell.execute_reply": "2025-11-24T08:12:59.164694Z"
    },
    "id": "_aQNVDH9GbE_",
    "outputId": "bd82323b-d6a3-4a91-a754-50285871131b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID=4105,\r\n",
      "PID=4106,\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d' ' -f2 slurm-{JOB_ID}.out |grep PID| sort | uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1r7TNigGcGI"
   },
   "source": [
    "We can also see which numbers were picked by each process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.168170Z",
     "iopub.status.busy": "2025-11-24T08:12:59.167907Z",
     "iopub.status.idle": "2025-11-24T08:12:59.281780Z",
     "shell.execute_reply": "2025-11-24T08:12:59.281024Z"
    },
    "id": "TLSAq_b3GQUw",
    "outputId": "9372832c-be45-4e46-ed39-95a6a43a0046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID=4105, 08:12:46\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d' ' -f2,12 slurm-{JOB_ID}.out |grep PID| sort | uniq -f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.284669Z",
     "iopub.status.busy": "2025-11-24T08:12:59.284054Z",
     "iopub.status.idle": "2025-11-24T08:12:59.399039Z",
     "shell.execute_reply": "2025-11-24T08:12:59.398071Z"
    },
    "id": "GBz1pHcNzKm2",
    "outputId": "f7764cb3-e26c-44af-b178-520b1426e5e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId=3 JobName=Run in Parallel\r\n",
      "   UserId=root(0) GroupId=root(0) MCS_label=N/A\r\n",
      "   Priority=1 Nice=0 Account=(null) QOS=(null)\r\n",
      "   JobState=COMPLETED Reason=None Dependency=(null)\r\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\r\n",
      "   RunTime=00:00:10 TimeLimit=00:02:00 TimeMin=N/A\r\n",
      "   SubmitTime=2025-11-24T08:11:23 EligibleTime=2025-11-24T08:11:23\r\n",
      "   AccrueTime=2025-11-24T08:11:23\r\n",
      "   StartTime=2025-11-24T08:12:46 EndTime=2025-11-24T08:12:56 Deadline=N/A\r\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-24T08:12:46 Scheduler=Backfill\r\n",
      "   Partition=LocalQ AllocNode:Sid=runnervmg1sw1:2685\r\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\r\n",
      "   NodeList=localhost\r\n",
      "   BatchHost=localhost\r\n",
      "   NumNodes=1 NumCPUs=2 NumTasks=1 CPUs/Task=2 ReqB:S:C:T=0:0:*:*\r\n",
      "   ReqTRES=cpu=2,mem=100M,node=1,billing=2\r\n",
      "   AllocTRES=cpu=2,mem=100M,node=1,billing=2\r\n",
      "   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\r\n",
      "   MinCPUsNode=2 MinMemoryNode=100M MinTmpDiskNode=0\r\n",
      "   Features=(null) DelayBoot=00:00:00\r\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\r\n",
      "   Command=/home/runner/work/big_data/big_data/simple_job_parallel.sh\r\n",
      "   WorkDir=/home/runner/work/big_data/big_data\r\n",
      "   StdErr=/home/runner/work/big_data/big_data/slurm-3.out\r\n",
      "   StdIn=/dev/null\r\n",
      "   StdOut=/home/runner/work/big_data/big_data/slurm-3.out\r\n",
      "   Power=\r\n",
      "   TresPerTask=cpu:2\r\n",
      "   \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!scontrol show job {JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH5gYIBO82Fb"
   },
   "source": [
    "**Note:** Python's `multiprocessing.Pool.map()` automatically splits the computation into chunks (works for **any iterable**, not just numbers):\n",
    "* `range(1, 101)` ‚Üí 100 items: 1, 2, 3, ‚Ä¶, 100\n",
    "* `Pool(processes=2)` ‚Üí creates **2 worker processes**\n",
    "* `pool.map(add, range(1, 101))` splits the 100 items and for 2 processes, it might assign roughly:\n",
    "    | Process  | Items  |\n",
    "    | -------- | ------ |\n",
    "    | Worker 1 | 1‚Äì50   |\n",
    "    | Worker 2 | 51‚Äì100 |\n",
    "\n",
    "```\n",
    "    range(1, 101)  ‚Üí  [1, 2, 3, ..., 100]\n",
    "\n",
    "    Pool(processes=2)\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Worker 1      ‚îÇ   ‚îÇ Worker 2      ‚îÇ\n",
    "    ‚îÇ 1, 2, 3 ...50 ‚îÇ   ‚îÇ 51, 52 ...100 ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "    Each worker applies add(x) to its chunk\n",
    "    Results are collected and combined ‚Üí sum = 5050\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jnx75guCFmZk"
   },
   "source": [
    "## üöÄ Run multiple tasks with `srun`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.402179Z",
     "iopub.status.busy": "2025-11-24T08:12:59.401714Z",
     "iopub.status.idle": "2025-11-24T08:12:59.406940Z",
     "shell.execute_reply": "2025-11-24T08:12:59.406245Z"
    },
    "id": "8VDa3EgH6qF9",
    "outputId": "3a7f76f0-65d0-4584-82e2-ecc474acc4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simple_job_srun.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_job_srun.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=\"srun job\"  # name of the job\n",
    "#SBATCH --ntasks=2             # number of tasks\n",
    "#SBATCH --cpus-per-task=1      # we just have 2 CPUs on COlab\n",
    "#SBATCH --mem=100M\n",
    "#SBATCH --time=00:02:00        # HH:MM:SS format\n",
    "\n",
    "# Ensure psutil is installed\n",
    "if ! python3 -c \"import psutil\" 2>/dev/null; then\n",
    "    sudo apt update && sudo apt install -y python3-psutil\n",
    "fi\n",
    "\n",
    "echo \"Job started on $(hostname) at $(date)\"\n",
    "echo \"Running on node: $SLURM_NODELIST\"\n",
    "echo \"Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Calculating sum of numbers from 1 to 100 with srun ...\"\n",
    "\n",
    "python3 -c \"\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "def add(x):\n",
    "    # Log PID and CPU affinity\n",
    "    process = psutil.Process()\n",
    "    cpu_affinity = process.cpu_affinity()\n",
    "    start_time = time.ctime(process.create_time())\n",
    "    print(f'Process PID={os.getpid()}, CPU affinity={cpu_affinity}, Start time={start_time}, x={x}')\n",
    "    return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = sum(map(add, range(1, 101)))\n",
    "    print(f'Sum of numbers: {result}')\n",
    "\"\n",
    "\n",
    "sleep 10\n",
    "echo \"Job finished at $(date)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.409129Z",
     "iopub.status.busy": "2025-11-24T08:12:59.408739Z",
     "iopub.status.idle": "2025-11-24T08:12:59.421665Z",
     "shell.execute_reply": "2025-11-24T08:12:59.420932Z"
    },
    "id": "l_rfl0ZoB9lq"
   },
   "outputs": [],
   "source": [
    "%%bash --out id\n",
    "sbatch simple_job_srun.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.424402Z",
     "iopub.status.busy": "2025-11-24T08:12:59.423873Z",
     "iopub.status.idle": "2025-11-24T08:12:59.534358Z",
     "shell.execute_reply": "2025-11-24T08:12:59.533637Z"
    },
    "id": "5UVwLORdB9lr",
    "outputId": "fd28c161-88fd-4f78-e6f6-a6cba9c324c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 4\r\n"
     ]
    }
   ],
   "source": [
    "!echo {id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.536774Z",
     "iopub.status.busy": "2025-11-24T08:12:59.536553Z",
     "iopub.status.idle": "2025-11-24T08:12:59.540086Z",
     "shell.execute_reply": "2025-11-24T08:12:59.539387Z"
    },
    "id": "dDRlp4NxIItS"
   },
   "outputs": [],
   "source": [
    "JOB_ID = id.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:12:59.542305Z",
     "iopub.status.busy": "2025-11-24T08:12:59.541958Z",
     "iopub.status.idle": "2025-11-24T08:13:29.747563Z",
     "shell.execute_reply": "2025-11-24T08:13:29.746795Z"
    },
    "id": "afacaaa3",
    "outputId": "1bc0ca0f-d9e2-48fa-fcc4-f00091be7002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 4 to finish...\n",
      "                 4    LocalQ srun job     root PD       0:00      1 (None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 4 to finish...\n",
      "                 4    LocalQ srun job     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 4 to finish...\n",
      "                 4    LocalQ srun job     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 4 to finish...\n",
      "                 4    LocalQ srun job     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 4 to finish...\n",
      "                 4    LocalQ srun job     root  R       0:03      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job 4 to finish...\n",
      "                 4    LocalQ srun job     root  R       0:08      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 4 finished.\n",
      "Job started on runnervmg1sw1 at Mon Nov 24 08:13:16 UTC 2025\r\n",
      "Running on node: localhost\r\n",
      "Job ID: 4\r\n",
      "Calculating sum of numbers from 1 to 100 with srun ...\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=1\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=2\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=3\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=4\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=5\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=6\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=7\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=8\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=9\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=10\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=11\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=12\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=13\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=14\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=15\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=16\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=17\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=18\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=19\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=20\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=21\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=22\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=23\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=24\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=25\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=26\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=27\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=28\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=29\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=30\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=31\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=32\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=33\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=34\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=35\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=36\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=37\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=38\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=39\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=40\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=41\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=42\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=43\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=44\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=45\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=46\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=47\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=48\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=49\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=50\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=51\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=52\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=53\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=54\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=55\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=56\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=57\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=58\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=59\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=60\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=61\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=62\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=63\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=64\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=65\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=66\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=67\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=68\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=69\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=70\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=71\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=72\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=73\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=74\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=75\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=76\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=77\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=78\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=79\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=80\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=81\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=82\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=83\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=84\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=85\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=86\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=87\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=88\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=89\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=90\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=91\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=92\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=93\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=94\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=95\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=96\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=97\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=98\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=99\r\n",
      "Process PID=4184, CPU affinity=[0, 1, 2, 3], Start time=Mon Nov 24 08:13:16 2025, x=100\r\n",
      "Sum of numbers: 5050\r\n",
      "Job finished at Mon Nov 24 08:13:26 UTC 2025\r\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Wait for the job to finish with a timeout\n",
    "timeout = 30 # seconds\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    result = !squeue -j {JOB_ID} -h\n",
    "    if not result:  # squeue returns empty if job is not in queue\n",
    "        print(f\"Job {JOB_ID} finished.\")\n",
    "        break\n",
    "    elif time.time() - start_time > timeout:\n",
    "        print(f\"Timeout ({timeout} seconds) reached. Job {JOB_ID} may still be running or have failed.\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Waiting for job {JOB_ID} to finish...\")\n",
    "        print(\"\\n\".join(result))\n",
    "        time.sleep(5) # Wait for 5 seconds before checking again\n",
    "\n",
    "# After the job is finished (or timeout), you can attempt to view the output files\n",
    "!cat slurm-{JOB_ID}.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uhk51XnqCOXB"
   },
   "source": [
    "But in this case we only ran one process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:29.750061Z",
     "iopub.status.busy": "2025-11-24T08:13:29.749836Z",
     "iopub.status.idle": "2025-11-24T08:13:29.862955Z",
     "shell.execute_reply": "2025-11-24T08:13:29.862220Z"
    },
    "id": "eRu-PXfqCDRq",
    "outputId": "537bf446-675d-4a6d-e4b0-6f7242213318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID=4184,\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d' ' -f2 slurm-{JOB_ID}.out |grep PID| sort | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:29.865466Z",
     "iopub.status.busy": "2025-11-24T08:13:29.865267Z",
     "iopub.status.idle": "2025-11-24T08:13:29.978987Z",
     "shell.execute_reply": "2025-11-24T08:13:29.978241Z"
    },
    "id": "CxwVhGWBJaiS",
    "outputId": "db50536a-4a4d-46eb-9734-fd44f7ce1eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID=4184, 08:13:16\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d' ' -f2,12 slurm-{JOB_ID}.out |grep PID| sort | uniq -f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52PiOd20JlaE"
   },
   "source": [
    "Even though $2$ CPUs were reserved, `srun` did not automatically split the job into two tasks, but instead ran the job on one CPU while keeping the second one reserved (and idle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:29.981557Z",
     "iopub.status.busy": "2025-11-24T08:13:29.981334Z",
     "iopub.status.idle": "2025-11-24T08:13:30.096470Z",
     "shell.execute_reply": "2025-11-24T08:13:30.095561Z"
    },
    "id": "JL98l_IeCHSC",
    "outputId": "5eb10877-96b6-4e64-edad-08fb0f0ac632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId=4 JobName=srun job\r\n",
      "   UserId=root(0) GroupId=root(0) MCS_label=N/A\r\n",
      "   Priority=1 Nice=0 Account=(null) QOS=(null)\r\n",
      "   JobState=COMPLETED Reason=None Dependency=(null)\r\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\r\n",
      "   RunTime=00:00:10 TimeLimit=00:02:00 TimeMin=N/A\r\n",
      "   SubmitTime=2025-11-24T08:12:59 EligibleTime=2025-11-24T08:12:59\r\n",
      "   AccrueTime=2025-11-24T08:12:59\r\n",
      "   StartTime=2025-11-24T08:13:16 EndTime=2025-11-24T08:13:26 Deadline=N/A\r\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-24T08:13:16 Scheduler=Backfill\r\n",
      "   Partition=LocalQ AllocNode:Sid=runnervmg1sw1:2685\r\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\r\n",
      "   NodeList=localhost\r\n",
      "   BatchHost=localhost\r\n",
      "   NumNodes=1 NumCPUs=2 NumTasks=2 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\r\n",
      "   ReqTRES=cpu=2,mem=100M,node=1,billing=2\r\n",
      "   AllocTRES=cpu=2,mem=100M,node=1,billing=2\r\n",
      "   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\r\n",
      "   MinCPUsNode=1 MinMemoryNode=100M MinTmpDiskNode=0\r\n",
      "   Features=(null) DelayBoot=00:00:00\r\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\r\n",
      "   Command=/home/runner/work/big_data/big_data/simple_job_srun.sh\r\n",
      "   WorkDir=/home/runner/work/big_data/big_data\r\n",
      "   StdErr=/home/runner/work/big_data/big_data/slurm-4.out\r\n",
      "   StdIn=/dev/null\r\n",
      "   StdOut=/home/runner/work/big_data/big_data/slurm-4.out\r\n",
      "   Power=\r\n",
      "   TresPerTask=cpu:1\r\n",
      "   \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!scontrol show job {JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKWvJ3qjJ69E"
   },
   "source": [
    "With `srun` it's up to us to specify how to split the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:30.099172Z",
     "iopub.status.busy": "2025-11-24T08:13:30.098869Z",
     "iopub.status.idle": "2025-11-24T08:13:30.104186Z",
     "shell.execute_reply": "2025-11-24T08:13:30.103446Z"
    },
    "id": "Cbm1MZpGKGJ7",
    "outputId": "b094f0d9-2dbb-4f98-85f8-3537241a3e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simple_job_srun_manual_split.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_job_srun_manual_split.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=\"srun job\"  # name of the job\n",
    "#SBATCH --ntasks=2             # number of tasks\n",
    "#SBATCH --cpus-per-task=1      # we just have 2 CPUs on COlab\n",
    "#SBATCH --mem=100M\n",
    "#SBATCH --time=00:02:00        # HH:MM:SS format\n",
    "\n",
    "# Ensure psutil is installed\n",
    "if ! python3 -c \"import psutil\" 2>/dev/null; then\n",
    "    sudo apt update && sudo apt install -y python3-psutil\n",
    "fi\n",
    "\n",
    "echo \"Job started on $(hostname) at $(date)\"\n",
    "echo \"Running on node: $SLURM_NODELIST\"\n",
    "echo \"Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Calculating sum of numbers from 1 to 100 with srun ...\"\n",
    "\n",
    "# Launch Python for each SLURM task\n",
    "srun python3 - <<EOF\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "def add(x):\n",
    "    # Log PID and CPU affinity\n",
    "    process = psutil.Process()\n",
    "    cpu_affinity = process.cpu_affinity()\n",
    "    start_time = time.ctime(process.create_time())\n",
    "    print(f'Process PID={os.getpid()}, CPU affinity={cpu_affinity}, Start time={start_time}, x={x}')\n",
    "    return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # SLURM environment variables\n",
    "    task_id = int(os.environ.get(\"SLURM_PROCID\", 0))\n",
    "    ntasks = int(os.environ.get(\"SLURM_NTASKS\", 1))\n",
    "\n",
    "    # Split the range across tasks\n",
    "    total = 100\n",
    "    chunk_size = total // ntasks\n",
    "    start = task_id * chunk_size + 1\n",
    "    end = (task_id + 1) * chunk_size if task_id != ntasks - 1 else total\n",
    "\n",
    "    # Compute partial sum\n",
    "    result = sum(map(add, range(start, end + 1)))\n",
    "    print(f\"Task {task_id}: sum({start}..{end}) = {result}\")\n",
    "\n",
    "EOF\n",
    "\n",
    "sleep 10\n",
    "echo \"Job finished at $(date)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:30.106272Z",
     "iopub.status.busy": "2025-11-24T08:13:30.106074Z",
     "iopub.status.idle": "2025-11-24T08:13:30.118993Z",
     "shell.execute_reply": "2025-11-24T08:13:30.118299Z"
    },
    "id": "jVwyexBvPSlo"
   },
   "outputs": [],
   "source": [
    "%%bash --out id\n",
    "sbatch simple_job_srun_manual_split.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:30.121596Z",
     "iopub.status.busy": "2025-11-24T08:13:30.121089Z",
     "iopub.status.idle": "2025-11-24T08:13:30.231704Z",
     "shell.execute_reply": "2025-11-24T08:13:30.230993Z"
    },
    "id": "R31dwxDUPSlo",
    "outputId": "0cb62fd4-0ade-4f54-fe2d-07751283c991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 5\r\n"
     ]
    }
   ],
   "source": [
    "!echo {id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:30.234284Z",
     "iopub.status.busy": "2025-11-24T08:13:30.233835Z",
     "iopub.status.idle": "2025-11-24T08:13:30.236931Z",
     "shell.execute_reply": "2025-11-24T08:13:30.236393Z"
    },
    "id": "8tAubOxOPSlo"
   },
   "outputs": [],
   "source": [
    "JOB_ID = id.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:30.239144Z",
     "iopub.status.busy": "2025-11-24T08:13:30.238739Z",
     "iopub.status.idle": "2025-11-24T08:13:30.352997Z",
     "shell.execute_reply": "2025-11-24T08:13:30.352252Z"
    },
    "id": "CUsNuDUEPiqO",
    "outputId": "25f98c56-eb02-4ff4-ea5c-55079f3c39b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId=5 JobName=srun job\r\n",
      "   UserId=root(0) GroupId=root(0) MCS_label=N/A\r\n",
      "   Priority=1 Nice=0 Account=(null) QOS=(null)\r\n",
      "   JobState=PENDING Reason=None Dependency=(null)\r\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\r\n",
      "   RunTime=00:00:00 TimeLimit=00:02:00 TimeMin=N/A\r\n",
      "   SubmitTime=2025-11-24T08:13:30 EligibleTime=2025-11-24T08:13:30\r\n",
      "   AccrueTime=Unknown\r\n",
      "   StartTime=Unknown EndTime=Unknown Deadline=N/A\r\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-24T08:13:30 Scheduler=Main\r\n",
      "   Partition=LocalQ AllocNode:Sid=runnervmg1sw1:2685\r\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\r\n",
      "   NodeList=\r\n",
      "   NumNodes=1 NumCPUs=2 NumTasks=2 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\r\n",
      "   ReqTRES=cpu=2,mem=100M,node=1,billing=2\r\n",
      "   AllocTRES=(null)\r\n",
      "   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\r\n",
      "   MinCPUsNode=1 MinMemoryNode=100M MinTmpDiskNode=0\r\n",
      "   Features=(null) DelayBoot=00:00:00\r\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\r\n",
      "   Command=/home/runner/work/big_data/big_data/simple_job_srun_manual_split.sh\r\n",
      "   WorkDir=/home/runner/work/big_data/big_data\r\n",
      "   StdErr=/home/runner/work/big_data/big_data/slurm-5.out\r\n",
      "   StdIn=/dev/null\r\n",
      "   StdOut=/home/runner/work/big_data/big_data/slurm-5.out\r\n",
      "   Power=\r\n",
      "   TresPerTask=cpu:1\r\n",
      "   \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!scontrol show job {JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:30.355417Z",
     "iopub.status.busy": "2025-11-24T08:13:30.355214Z",
     "iopub.status.idle": "2025-11-24T08:13:35.575855Z",
     "shell.execute_reply": "2025-11-24T08:13:35.575038Z"
    },
    "id": "As0ynV5aPsMH",
    "outputId": "fc6dc8f1-8d47-4299-92e5-d86e0181b6b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: slurm-5.out: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!sleep 5\n",
    "!cat slurm-{JOB_ID}.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3DgF1VERch8"
   },
   "source": [
    "Now the computation was split into two tasks, each task had its own process and the two processes ran simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:35.578381Z",
     "iopub.status.busy": "2025-11-24T08:13:35.578174Z",
     "iopub.status.idle": "2025-11-24T08:13:35.691305Z",
     "shell.execute_reply": "2025-11-24T08:13:35.690534Z"
    },
    "id": "7ykU5BrbPSlp",
    "outputId": "32bee5db-1e20-4f10-a741-8ca47c5aec62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut: slurm-5.out: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d' ' -f2 slurm-{JOB_ID}.out |grep PID| sort | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:35.693759Z",
     "iopub.status.busy": "2025-11-24T08:13:35.693552Z",
     "iopub.status.idle": "2025-11-24T08:13:35.807241Z",
     "shell.execute_reply": "2025-11-24T08:13:35.806509Z"
    },
    "id": "92z9_UunPSlp",
    "outputId": "e2d2b6d8-2e7e-46da-81b2-d6ad6298199b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut: slurm-5.out: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d' ' -f2,12 slurm-{JOB_ID}.out |grep PID| sort | uniq -f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WImegEuy5qAE"
   },
   "source": [
    "> ## üìå Recap: how to run a SLURM job\n",
    ">\n",
    "> * Start your script with the shebang `#!/bin/bash`\n",
    "> * Use SBATCH directives to request resources: `#SBATCH --option=value`\n",
    "> * Do **not** insert empty lines between the shebang and SBATCH directives\n",
    "> * Most common directives: `--job-name`, `--output`, `--error`, `--partition`, `--ntasks`, `--cpus-per-task`, `--mem`, `--time`\n",
    "> * Write your commands **after the directives**, e.g., `python my_script.py`\n",
    "> * Run $2$ tasks in parallel with `--ntasks=1`, `--cpus-per-task=2`, and Python's `multiprocessing` with `Pool(2)`\n",
    "> * Use `srun` for parallel execution with `--ntasks` ‚â•$1$ but take care of splitting the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-QTevQSJjJM"
   },
   "source": [
    "## üöÄ SLURM Job Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3348bc9"
   },
   "source": [
    "Here is a simple script to demonstrate SLURM job arrays. Each task in the array will print its assigned `SLURM_ARRAY_TASK_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:35.810083Z",
     "iopub.status.busy": "2025-11-24T08:13:35.809623Z",
     "iopub.status.idle": "2025-11-24T08:13:35.814105Z",
     "shell.execute_reply": "2025-11-24T08:13:35.813556Z"
    },
    "id": "ca75c1ce",
    "outputId": "613ae13c-68c5-406c-ad29-3abbf4079a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simple_array_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_array_job.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --partition=LocalQ\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --output=array_output_%A_%a.out\n",
    "#SBATCH --array=0-3  # This creates a job array with tasks 0, 1, 2, and 3\n",
    "\n",
    "echo \"This is array task $SLURM_ARRAY_TASK_ID of job $SLURM_JOB_ID\"\n",
    "echo \"Running on node: $SLURM_NODELIST\"\n",
    "sleep 5 # Simulate some work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:35.815988Z",
     "iopub.status.busy": "2025-11-24T08:13:35.815777Z",
     "iopub.status.idle": "2025-11-24T08:13:35.926820Z",
     "shell.execute_reply": "2025-11-24T08:13:35.926001Z"
    },
    "id": "8c171181"
   },
   "outputs": [],
   "source": [
    "# Make the script executable\n",
    "!chmod +x simple_array_job.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:35.929334Z",
     "iopub.status.busy": "2025-11-24T08:13:35.928963Z",
     "iopub.status.idle": "2025-11-24T08:13:35.942251Z",
     "shell.execute_reply": "2025-11-24T08:13:35.941411Z"
    },
    "id": "xUPZcDTAOkzZ"
   },
   "outputs": [],
   "source": [
    "%%bash --out id\n",
    "sbatch simple_array_job.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:35.944575Z",
     "iopub.status.busy": "2025-11-24T08:13:35.944195Z",
     "iopub.status.idle": "2025-11-24T08:13:36.054826Z",
     "shell.execute_reply": "2025-11-24T08:13:36.053896Z"
    },
    "id": "xaK_nI1VKZZp",
    "outputId": "021bc76c-38f6-445c-f692-0c362e829d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 6\r\n"
     ]
    }
   ],
   "source": [
    "!echo {id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:36.057960Z",
     "iopub.status.busy": "2025-11-24T08:13:36.057299Z",
     "iopub.status.idle": "2025-11-24T08:13:36.061104Z",
     "shell.execute_reply": "2025-11-24T08:13:36.060394Z"
    },
    "id": "A51WVhrIKZZp"
   },
   "outputs": [],
   "source": [
    "JOB_ID = id.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:36.063413Z",
     "iopub.status.busy": "2025-11-24T08:13:36.063037Z",
     "iopub.status.idle": "2025-11-24T08:13:36.177454Z",
     "shell.execute_reply": "2025-11-24T08:13:36.176576Z"
    },
    "id": "2eafbd97",
    "outputId": "2251c33f-ebf0-4a21-8494-43990eb33a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\r\n",
      "                 5    LocalQ srun job     root PD       0:00      1 (InvalidAccount)\r\n"
     ]
    }
   ],
   "source": [
    "# Check the job status (optional)\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW9pkCTdH0Fi"
   },
   "source": [
    "If the jobs are not yet finished, you will get an error when you try to view the output files.\n",
    "\n",
    "```\n",
    "cat: 'array_output_*.out': No such file or directory\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:36.180306Z",
     "iopub.status.busy": "2025-11-24T08:13:36.179777Z",
     "iopub.status.idle": "2025-11-24T08:13:36.291673Z",
     "shell.execute_reply": "2025-11-24T08:13:36.290778Z"
    },
    "id": "7-m6lyZDLNXh",
    "outputId": "59248c50-de85-4769-8cbf-b65db56f6350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: 'array_output_*.out': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat array_output_*.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzdhw7n9H7JA"
   },
   "source": [
    "After the jobs are finished, you can view the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:13:36.294533Z",
     "iopub.status.busy": "2025-11-24T08:13:36.293992Z",
     "iopub.status.idle": "2025-11-24T08:15:56.830969Z",
     "shell.execute_reply": "2025-11-24T08:15:56.830185Z"
    },
    "id": "VtuEXWDmLHHF",
    "outputId": "8d403651-bc09-4047-eb2f-d6ac24b5bd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n",
      "                 5    LocalQ srun job     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n",
      "                 5    LocalQ srun job     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n",
      "                 5    LocalQ srun job     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (None)\n",
      "                 5    LocalQ srun job     root  R       0:05      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (None)\n",
      "                 5    LocalQ srun job     root  R       0:10      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[0-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[1-3]    LocalQ simple_a     root PD       0:00      1 (None)\n",
      "               6_0    LocalQ simple_a     root  R       0:05      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[1-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[1-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[1-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[1-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[1-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[2-3]    LocalQ simple_a     root PD       0:00      1 (None)\n",
      "               6_1    LocalQ simple_a     root  R       0:05      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[2-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[2-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[2-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[2-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           6_[2-3]    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               6_3    LocalQ simple_a     root PD       0:00      1 (None)\n",
      "               6_2    LocalQ simple_a     root  R       0:05      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               6_3    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               6_3    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               6_3    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               6_3    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               6_3    LocalQ simple_a     root PD       0:00      1 (InvalidAccount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to finish...\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               6_3    LocalQ simple_a     root  R       0:05      1 localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jobs finished.\n",
      "This is array task 0 of job 7\r\n",
      "Running on node: localhost\r\n",
      "This is array task 1 of job 8\r\n",
      "Running on node: localhost\r\n",
      "This is array task 2 of job 9\r\n",
      "Running on node: localhost\r\n",
      "This is array task 3 of job 6\r\n",
      "Running on node: localhost\r\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Wait for all jobs to finish\n",
    "while True:\n",
    "    result = !squeue -u $(id -u)\n",
    "    # Check if the output contains more than just the header\n",
    "    if len(result) <= 1:\n",
    "        print(\"All jobs finished.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Waiting for jobs to finish...\")\n",
    "        print(\"\\n\".join(result))\n",
    "        time.sleep(5) # Wait for 5 seconds before checking again\n",
    "\n",
    "# After the jobs are finished, you can view the output files\n",
    "!cat array_output_*.out"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPOFSBER6jhAr+ir3ZBicnW",
   "collapsed_sections": [
    "ukIg5iRf3yoD",
    "2QpF7XoRzry7",
    "brQkWtmMi786",
    "31Q0HgWMK19o",
    "VFtQ9QQgj98S",
    "sml8t6rVM17l",
    "BhhgV7kNYT7c",
    "XhJQeLeT99Tz",
    "3d8C0ay3Xa-d",
    "gFMWSBKBX7Yl",
    "92wZzJmSfK35",
    "Ua-nBgvmsJpA",
    "1DAjlH9ltWXj",
    "uH60mvkDzzFk",
    "Jnx75guCFmZk",
    "H-QTevQSJjJM"
   ],
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
